#!/usr/bin/env python3
"""
ETP Trainer - ç®€åŒ–ç‰ˆæœ¬ç”¨äºæ¨ç†
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, Optional, List
import os

try:
    from habitat import Config
    print("âœ… Habitat Config å¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âŒ Habitat Config å¯¼å…¥å¤±è´¥")
    class Config:
        def __init__(self):
            pass
        def merge_from_file(self, file_path):
            pass
        def defrost(self):
            pass
        def freeze(self):
            pass

class RLTrainer:
    """
    å¼ºåŒ–å­¦ä¹ è®­ç»ƒå™¨ - æ¨ç†ä¸“ç”¨ç‰ˆæœ¬
    """
    
    def __init__(self, config: Config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ¨¡å‹ç»„ä»¶
        self.actor_critic = None
        self.agent = None
        
        print(f"ğŸ¤– RLTrainer åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        
        # å°è¯•æ„å»ºæ¨¡å‹
        self._build_model()
    
    def _build_model(self):
        """æ„å»ºæ¨¡å‹æ¶æ„"""
        try:
            # è¿™é‡Œåº”è¯¥æ ¹æ®å®é™…çš„ ETPNav æ¶æ„æ¥æ„å»º
            # æš‚æ—¶åˆ›å»ºå ä½ç¬¦
            print("ğŸ”§ æ„å»ºæ¨¡å‹æ¶æ„...")
            
            # åˆ›å»ºç®€å•çš„å ä½ç¬¦æ¨¡å‹
            class SimplePolicy(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.rgb_encoder = nn.Sequential(
                        nn.Conv2d(3, 32, 3, stride=2, padding=1),
                        nn.ReLU(),
                        nn.AdaptiveAvgPool2d((1, 1)),
                        nn.Flatten()
                    )
                    self.depth_encoder = nn.Sequential(
                        nn.Conv2d(1, 16, 3, stride=2, padding=1), 
                        nn.ReLU(),
                        nn.AdaptiveAvgPool2d((1, 1)),
                        nn.Flatten()
                    )
                    self.action_head = nn.Linear(48, 4)  # 4ä¸ªåŠ¨ä½œ
                
                def forward(self, observations):
                    rgb = observations.get('rgb', torch.zeros(1, 3, 480, 640))
                    depth = observations.get('depth', torch.zeros(1, 1, 480, 640))
                    
                    if rgb.dim() == 4 and rgb.shape[1] == 3:
                        rgb_feat = self.rgb_encoder(rgb)
                    else:
                        rgb_feat = torch.zeros(rgb.shape[0], 32)
                    
                    if depth.dim() == 4 and depth.shape[1] == 1:
                        depth_feat = self.depth_encoder(depth)
                    else:
                        depth_feat = torch.zeros(depth.shape[0], 16)
                    
                    combined = torch.cat([rgb_feat, depth_feat], dim=1)
                    actions = self.action_head(combined)
                    
                    return actions
            
            self.actor_critic = SimplePolicy().to(self.device)
            print("âœ… æ¨¡å‹æ¶æ„æ„å»ºå®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹æ„å»ºè­¦å‘Š: {e}")
            self.actor_critic = None
    
    def load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        if not os.path.exists(checkpoint_path):
            raise FileNotFoundError(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        
        print(f"ğŸ”„ åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        
        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            print(f"ğŸ“‹ æ£€æŸ¥ç‚¹é”®å€¼: {list(checkpoint.keys())}")
            
            # å°è¯•ä¸åŒçš„åŠ è½½ç­–ç•¥
            if self.actor_critic is not None:
                if 'state_dict' in checkpoint:
                    self.actor_critic.load_state_dict(checkpoint['state_dict'], strict=False)
                    print("âœ… é€šè¿‡ state_dict åŠ è½½")
                elif 'model' in checkpoint:
                    self.actor_critic.load_state_dict(checkpoint['model'], strict=False)
                    print("âœ… é€šè¿‡ model åŠ è½½")
                else:
                    # å°è¯•ç›´æ¥åŠ è½½
                    self.actor_critic.load_state_dict(checkpoint, strict=False)
                    print("âœ… ç›´æ¥åŠ è½½")
            
            print("âœ… æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def inference(self, observations: Dict[str, torch.Tensor]) -> int:
        """æ¨ç†æ¥å£"""
        if self.actor_critic is None:
            return 1  # é»˜è®¤å‰è¿›
        
        try:
            self.actor_critic.eval()
            with torch.no_grad():
                action_logits = self.actor_critic(observations)
                action = torch.argmax(action_logits, dim=1).item()
                return action
        except Exception as e:
            print(f"âš ï¸ æ¨ç†å¤±è´¥: {e}")
            return 1  # é»˜è®¤å‰è¿›

print("âœ… vlnce_baselines.ss_trainer_ETP æ¨¡å—åŠ è½½å®Œæˆ")
