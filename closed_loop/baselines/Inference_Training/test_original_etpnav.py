#!/usr/bin/env python3
"""
åŸæ¨¡å‹æµ‹è¯•å™¨ - åŸºäºæ–°è®­ç»ƒé…ç½®
ä¿æŒå¯¹åŸæ¨¡å‹æƒé‡ckpt.iter19600.pthçš„è°ƒç”¨ä¸å˜
ä½¿ç”¨ä¸æ–°è®­ç»ƒæ¨¡å‹ç›¸åŒçš„æµ‹è¯•é›†å’Œè¯„ä¼°æ–¹æ³•
"""

import sys
import os
import torch
import torch.nn as nn
import logging
import json
import zipfile
import io
import numpy as np
import gzip
import random
import time
from pathlib import Path
from collections import OrderedDict
import re

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class OriginalModelTester:
    """åŸæ¨¡å‹æµ‹è¯•å™¨ - ä¸æ–°è®­ç»ƒæ¨¡å‹ä½¿ç”¨ç›¸åŒé…ç½®"""
    
    def __init__(self):
        torch.manual_seed(42)
        np.random.seed(42)
        random.seed(42)
        
        self.device = torch.device('cpu')
        # ä¿æŒå¯¹åŸæ¨¡å‹æƒé‡çš„è°ƒç”¨ä¸å˜
        self.checkpoint_path = "/data/yinxy/etpnav_training_data/checkpoints/ckpt.iter19600.pth"
        
        logger.info("ğŸ¯ åŸæ¨¡å‹æµ‹è¯•å™¨ - åŸºäºæ–°è®­ç»ƒé…ç½®")
        logger.info(f"   è®¾å¤‡: {self.device}")
        logger.info(f"   åŸæ¨¡å‹æƒé‡: {self.checkpoint_path}")
        logger.info(f"   ç›®æ ‡: è·å–åŸæ¨¡å‹åœ¨ç›¸åŒæµ‹è¯•é›†ä¸Šçš„L2è¯¯å·®")
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        self._check_data_files()
        
        # ä½¿ç”¨ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ç›¸åŒçš„è¯æ±‡è¡¨æ„å»º
        self.build_vocabulary()
    
    def _check_data_files(self):
        """æ£€æŸ¥æ•°æ®æ–‡ä»¶ä½ç½®"""
        logger.info("ğŸ” æ£€æŸ¥æ•°æ®æ–‡ä»¶ä½ç½®...")
        
        # æ£€æŸ¥å½“å‰ç›®å½•ç»“æ„
        current_dir = os.getcwd()
        logger.info(f"   å½“å‰å·¥ä½œç›®å½•: {current_dir}")
        
        # æŸ¥æ‰¾å¯èƒ½çš„æ•°æ®ç›®å½•
        data_dirs_to_check = [
            "data",
            "data/datasets",
            "data/datasets/high_quality_vlnce_fixed",
            "../data",
            "../data/datasets", 
            "../data/datasets/high_quality_vlnce_fixed",
            "/data/yinxy/etpnav_training_data/data",
            "/data/yinxy/etpnav_training_data/data/datasets",
            "/data/yinxy/etpnav_training_data/data/datasets/high_quality_vlnce_fixed"
        ]
        
        for data_dir in data_dirs_to_check:
            if os.path.exists(data_dir):
                logger.info(f"   âœ… æ‰¾åˆ°ç›®å½•: {data_dir}")
                # åˆ—å‡ºç›®å½•å†…å®¹
                try:
                    files = os.listdir(data_dir)
                    json_files = [f for f in files if f.endswith(('.json', '.json.gz'))]
                    if json_files:
                        logger.info(f"      JSONæ–‡ä»¶: {json_files}")
                except:
                    pass
            else:
                logger.debug(f"   âŒ ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    def build_vocabulary(self):
        """æ„å»ºè¯æ±‡è¡¨ - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´"""
        logger.info("ğŸ“š æ„å»ºè¯æ±‡è¡¨ï¼ˆä¸æ–°è®­ç»ƒæ¨¡å‹ä¸€è‡´ï¼‰...")
        
        special_tokens = ['<pad>', '<unk>', '<start>', '<end>', '<stop>']
        
        # ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ç›¸åŒçš„è¯æ±‡è¡¨
        navigation_words = [
            # åŠ¨ä½œè¯
            'go', 'walk', 'turn', 'move', 'head', 'proceed', 'continue', 'stop', 'reach',
            'enter', 'exit', 'follow', 'toward', 'forward', 'back', 'backward', 'take',
            'face', 'approach', 'cross', 'pass', 'climb', 'descend', 'ascend',
            
            # æ–¹å‘è¯  
            'left', 'right', 'straight', 'up', 'down', 'north', 'south', 'east', 'west',
            'ahead', 'behind', 'around', 'through', 'past', 'over', 'under',
            
            # ä½ç½®è¯
            'area', 'room', 'door', 'hall', 'corridor', 'stairs', 'building', 'floor',
            'wall', 'corner', 'entrance', 'exit', 'lobby', 'office', 'kitchen', 'bathroom',
            'bedroom', 'living', 'dining', 'hallway', 'staircase', 'balcony',
            
            # ç‰©å“è¯
            'table', 'chair', 'bed', 'desk', 'window', 'shelf', 'cabinet', 'counter',
            'couch', 'sofa', 'tv', 'television', 'lamp', 'door', 'plant', 'picture',
            'mirror', 'sink', 'toilet', 'shower', 'oven', 'refrigerator', 'fridge',
            
            # ä¿®é¥°è¯
            'next', 'nearest', 'closest', 'first', 'second', 'third', 'last', 'final',
            'large', 'small', 'big', 'wooden', 'white', 'black', 'brown', 'blue',
            'red', 'green', 'open', 'closed', 'round', 'square',
            
            # è¿æ¥è¯å’Œä»‹è¯
            'the', 'a', 'an', 'to', 'from', 'in', 'on', 'at', 'of', 'for', 'with',
            'and', 'or', 'then', 'until', 'when', 'where', 'there', 'here', 'this', 'that',
            'by', 'near', 'beside', 'between', 'above', 'below', 'inside', 'outside',
            
            # å…¶ä»–å¸¸ç”¨è¯
            'is', 'are', 'your', 'goal', 'located', 'find', 'see', 'look', 'will', 'should',
            'now', 'then', 'after', 'before', 'once', 'you', 'it', 'they', 'them'
        ]
        
        self.vocab = {token: idx for idx, token in enumerate(special_tokens + navigation_words)}
        self.vocab_size = len(self.vocab)
        self.pad_token_id = self.vocab['<pad>']
        self.unk_token_id = self.vocab['<unk>']
        self.stop_token_id = self.vocab['<stop>']
        
        logger.info(f"âœ… è¯æ±‡è¡¨æ„å»ºå®Œæˆï¼Œå¤§å°: {self.vocab_size}")
    
    def extract_original_weights(self):
        """æå–åŸå§‹æƒé‡ - ä¿æŒåŸæœ‰æ–¹æ³•ä¸å˜"""
        logger.info("ğŸ”§ æå–åŸå§‹æƒé‡...")
        
        try:
            weights_dict = {}
            
            with zipfile.ZipFile(self.checkpoint_path, 'r') as zip_file:
                # è¯»å–data.pklä»¥è·å–ç»“æ„
                with zip_file.open('archive/data.pkl') as pkl_file:
                    pkl_data = pkl_file.read()
                
                # æå–æ‰€æœ‰tensoræ•°æ®
                tensor_files = [f for f in zip_file.namelist() if f.startswith('archive/data/') and f != 'archive/data.pkl']
                logger.info(f"ğŸ“Š å‘ç° {len(tensor_files)} ä¸ªtensoræ–‡ä»¶")
                
                # è¯»å–æ¯ä¸ªtensor
                tensor_data = {}
                for tensor_file in tensor_files:
                    tensor_id = tensor_file.split('/')[-1]
                    with zip_file.open(tensor_file) as f:
                        tensor_bytes = f.read()
                        tensor_data[tensor_id] = tensor_bytes
                
                # åˆ†æpklå†…å®¹ä»¥ç†è§£ç»“æ„
                pkl_str = pkl_data.decode('latin1', errors='ignore')
                
                # æ”¹è¿›çš„æƒé‡åç§°æå–
                weight_patterns = [
                    r'(net\.module\.[a-zA-Z0-9_.]+\.(?:weight|bias))',
                    r'(vln_bert\.[a-zA-Z0-9_.]+\.(?:weight|bias))',
                    r'(depth_encoder\.[a-zA-Z0-9_.]+\.(?:weight|bias))',
                    r'(rgb_encoder\.[a-zA-Z0-9_.]+\.(?:weight|bias))',
                    r'([a-zA-Z0-9_.]+\.(?:weight|bias))'
                ]
                
                found_weights = set()
                for pattern in weight_patterns:
                    matches = re.findall(pattern, pkl_str)
                    for match in matches:
                        if len(match) > 5 and '.' in match:  # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„æƒé‡å
                            found_weights.add(match)
                
                logger.info(f"ğŸ” å‘ç° {len(found_weights)} ä¸ªæƒé‡åç§°")
                
                # ä¸ºæ¯ä¸ªæƒé‡åˆ›å»ºtensor
                sorted_weights = sorted(found_weights)
                for i, weight_name in enumerate(sorted_weights):
                    if i < len(tensor_data):
                        tensor_id = str(i)
                        if tensor_id in tensor_data:
                            bytes_data = tensor_data[tensor_id]
                            
                            # æ™ºèƒ½tensoré‡å»º
                            tensor = self._reconstruct_tensor_smart(weight_name, bytes_data)
                            if tensor is not None:
                                weights_dict[weight_name] = tensor
                                logger.debug(f"   é‡å»º {weight_name}: {tensor.shape}")
                
                logger.info(f"âœ… æˆåŠŸé‡å»º {len(weights_dict)} ä¸ªæƒé‡")
                return weights_dict
                
        except Exception as e:
            logger.error(f"âŒ æƒé‡æå–å¤±è´¥: {e}")
            return None
    
    def _reconstruct_tensor_smart(self, weight_name, bytes_data):
        """æ™ºèƒ½tensoré‡å»º - ä¿æŒåŸæœ‰æ–¹æ³•"""
        if len(bytes_data) < 4:
            return None
        
        try:
            # æ ¹æ®æƒé‡åæ¨æ–­æ•°æ®ç±»å‹å’Œå½¢çŠ¶
            num_floats = len(bytes_data) // 4
            float_array = np.frombuffer(bytes_data, dtype=np.float32)
            
            if len(float_array) == 0:
                return None
            
            tensor = torch.from_numpy(float_array.copy())
            
            # æ ¹æ®æƒé‡åç§°æ™ºèƒ½æ¨æ–­å½¢çŠ¶
            name_lower = weight_name.lower()
            
            if 'embeddings.word_embeddings.weight' in name_lower:
                # è¯åµŒå…¥: [vocab_size, embed_dim]
                if len(tensor) >= 768:
                    vocab_size = len(tensor) // 768
                    return tensor.view(vocab_size, 768)
            
            elif 'embeddings.position_embeddings.weight' in name_lower:
                # ä½ç½®åµŒå…¥: [max_pos, embed_dim]
                if len(tensor) >= 768:
                    max_pos = len(tensor) // 768
                    return tensor.view(max_pos, 768)
            
            elif 'attention.self.query.weight' in name_lower or 'attention.self.key.weight' in name_lower or 'attention.self.value.weight' in name_lower:
                # æ³¨æ„åŠ›æƒé‡: [hidden_dim, hidden_dim]
                sqrt_size = int(np.sqrt(len(tensor)))
                if sqrt_size * sqrt_size == len(tensor):
                    return tensor.view(sqrt_size, sqrt_size)
                elif len(tensor) >= 768:
                    return tensor.view(768, -1)
            
            elif 'attention.output.dense.weight' in name_lower:
                # æ³¨æ„åŠ›è¾“å‡º: [hidden_dim, hidden_dim]
                if len(tensor) >= 768:
                    return tensor.view(768, -1)
            
            elif 'intermediate.dense.weight' in name_lower:
                # Feed-forwardä¸­é—´å±‚: [hidden_dim, hidden_dim*4]
                if len(tensor) >= 768 * 4:
                    return tensor.view(768 * 4, 768)
                elif len(tensor) >= 768:
                    return tensor.view(-1, 768)
            
            elif 'output.dense.weight' in name_lower:
                # Feed-forwardè¾“å‡ºå±‚: [hidden_dim*4, hidden_dim]
                if len(tensor) >= 768 * 4:
                    return tensor.view(768, 768 * 4)
                elif len(tensor) >= 768:
                    return tensor.view(768, -1)
            
            elif 'layernorm.weight' in name_lower or 'layernorm.bias' in name_lower:
                # LayerNormå‚æ•°: [hidden_dim]
                if len(tensor) <= 1024:  # åˆç†çš„LayerNormå¤§å°
                    return tensor.view(-1)
            
            elif '.bias' in name_lower:
                # åç½®å‚æ•°: ä¿æŒä¸€ç»´
                return tensor.view(-1)
            
            elif 'conv' in name_lower and '.weight' in name_lower:
                # å·ç§¯æƒé‡: å°è¯•å¸¸è§çš„å·ç§¯å½¢çŠ¶
                if len(tensor) == 64 * 3 * 7 * 7:  # ç¬¬ä¸€å±‚å·ç§¯
                    return tensor.view(64, 3, 7, 7)
                elif len(tensor) == 128 * 64 * 3 * 3:  # åç»­å·ç§¯
                    return tensor.view(128, 64, 3, 3)
                elif len(tensor) == 256 * 128 * 3 * 3:
                    return tensor.view(256, 128, 3, 3)
                elif len(tensor) == 512 * 256 * 3 * 3:
                    return tensor.view(512, 256, 3, 3)
                else:
                    # å°è¯•é€šç”¨4Då½¢çŠ¶
                    total = len(tensor)
                    for out_ch in [64, 128, 256, 512]:
                        for in_ch in [3, 64, 128, 256]:
                            for k in [3, 5, 7]:
                                if total == out_ch * in_ch * k * k:
                                    return tensor.view(out_ch, in_ch, k, k)
            
            elif 'linear' in name_lower or 'fc' in name_lower:
                # çº¿æ€§å±‚æƒé‡
                if len(tensor) >= 768:
                    # å°è¯•å¸¸è§çš„çº¿æ€§å±‚å½¢çŠ¶
                    for out_dim in [768, 512, 256, 128, 64, 32, 4, 1]:
                        if len(tensor) % out_dim == 0:
                            in_dim = len(tensor) // out_dim
                            if in_dim <= 4096:  # åˆç†çš„è¾“å…¥ç»´åº¦
                                return tensor.view(out_dim, in_dim)
            
            # é»˜è®¤æƒ…å†µï¼šå°è¯•2Då½¢çŠ¶
            if len(tensor) > 1:
                # å°è¯•æ¥è¿‘æ­£æ–¹å½¢çš„å½¢çŠ¶
                sqrt_size = int(np.sqrt(len(tensor)))
                if sqrt_size > 1:
                    remainder = len(tensor) % sqrt_size
                    if remainder == 0:
                        return tensor.view(sqrt_size, sqrt_size)
                    elif len(tensor) >= 768:
                        return tensor.view(-1, 768)
                    else:
                        return tensor.view(-1, sqrt_size)
                else:
                    return tensor.view(-1)
            else:
                return tensor.view(-1)
                
        except Exception as e:
            logger.debug(f"   tensoré‡å»ºå¤±è´¥ {weight_name}: {e}")
            return None
    
    def create_compatible_model(self, original_weights):
        """åˆ›å»ºä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„å…¼å®¹çš„æ¨¡å‹"""
        logger.info("ğŸ—ï¸ åˆ›å»ºå…¼å®¹æ¨¡å‹æ¶æ„...")
        
        # åˆ†æåŸå§‹æƒé‡ç»“æ„
        weight_analysis = self._analyze_weight_structure(original_weights)
        
        # ä½¿ç”¨ä¸æ–°è®­ç»ƒæ¨¡å‹ç›¸åŒçš„é…ç½®
        hidden_size = 512  # ä¸æ–°è®­ç»ƒæ¨¡å‹ä¸€è‡´
        vocab_size = self.vocab_size  # ä½¿ç”¨ç›¸åŒçš„è¯æ±‡è¡¨å¤§å°
        
        logger.info(f"ğŸ“ æ¨¡å‹é…ç½®ï¼ˆä¸æ–°è®­ç»ƒæ¨¡å‹ä¸€è‡´ï¼‰: vocab={vocab_size}, hidden={hidden_size}")
        
        class CompatibleETPNavModel(nn.Module):
            def __init__(self, vocab_size, hidden_size=512):
                super().__init__()
                
                self.hidden_size = hidden_size
                self.vocab_size = vocab_size
                
                # æŒ‡ä»¤ç¼–ç å™¨ - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.instruction_embedding = nn.Embedding(vocab_size, 256, padding_idx=0)
                self.instruction_transformer = nn.TransformerEncoder(
                    nn.TransformerEncoderLayer(
                        d_model=256, 
                        nhead=8, 
                        dim_feedforward=512,
                        dropout=0.1,
                        batch_first=True
                    ),
                    num_layers=3
                )
                self.instruction_projection = nn.Linear(256, hidden_size)
                
                # è§†è§‰ç¼–ç å™¨ - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.visual_encoder = nn.Sequential(
                    nn.Conv2d(3, 64, 7, stride=2, padding=3),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(3, stride=2, padding=1),
                    
                    self._make_resnet_block(64, 128),
                    self._make_resnet_block(128, 256), 
                    self._make_resnet_block(256, 512),
                    
                    nn.AdaptiveAvgPool2d((1, 1)),
                    nn.Flatten(),
                    nn.Linear(512, hidden_size)
                )
                
                # æ·±åº¦ç¼–ç å™¨ - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.depth_encoder = nn.Sequential(
                    nn.Conv2d(1, 64, 7, stride=2, padding=3),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(3, stride=2, padding=1),
                    
                    self._make_resnet_block(64, 128),
                    self._make_resnet_block(128, 256),
                    self._make_resnet_block(256, 512),
                    
                    nn.AdaptiveAvgPool2d((1, 1)),
                    nn.Flatten(),
                    nn.Linear(512, hidden_size)
                )
                
                # è§†è§‰ç‰¹å¾èåˆ - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.visual_fusion = nn.Sequential(
                    nn.Linear(hidden_size * 2, hidden_size),
                    nn.LayerNorm(hidden_size),
                    nn.ReLU(),
                    nn.Dropout(0.1)
                )
                
                # è·¨æ¨¡æ€èåˆ - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.cross_modal_fusion = nn.TransformerEncoder(
                    nn.TransformerEncoderLayer(
                        d_model=hidden_size,
                        nhead=8,
                        dim_feedforward=hidden_size*2,
                        dropout=0.1,
                        batch_first=True
                    ),
                    num_layers=2
                )
                
                # è¾“å‡ºå¤´ - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.policy_head = nn.Sequential(
                    nn.Linear(hidden_size, hidden_size//2),
                    nn.LayerNorm(hidden_size//2),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(hidden_size//2, 4)  # STOP, FORWARD, TURN_LEFT, TURN_RIGHT
                )
                
                # Progress Monitor - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.progress_head = nn.Sequential(
                    nn.Linear(hidden_size, hidden_size//4),
                    nn.ReLU(),
                    nn.Linear(hidden_size//4, 1),
                    nn.Sigmoid()
                )
                
                # ä»·å€¼å‡½æ•° - ä¸æ–°è®­ç»ƒæ¨¡å‹æ¶æ„ä¸€è‡´
                self.value_head = nn.Sequential(
                    nn.Linear(hidden_size, hidden_size//4),
                    nn.ReLU(),
                    nn.Linear(hidden_size//4, 1)
                )
                
                # åˆå§‹åŒ–æƒé‡
                self._initialize_weights()
            
            def _initialize_weights(self):
                """åˆå§‹åŒ–æƒé‡ç¡®ä¿æ•°å€¼ç¨³å®šæ€§"""
                for module in self.modules():
                    if isinstance(module, nn.Linear):
                        nn.init.xavier_uniform_(module.weight)
                        if module.bias is not None:
                            nn.init.constant_(module.bias, 0)
                    elif isinstance(module, nn.LayerNorm):
                        nn.init.constant_(module.weight, 1)
                        nn.init.constant_(module.bias, 0)
            
            def _make_resnet_block(self, in_channels, out_channels, stride=2):
                return nn.Sequential(
                    nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1),
                    nn.BatchNorm2d(out_channels),
                    nn.ReLU(inplace=True),
                    nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),
                    nn.BatchNorm2d(out_channels),
                    nn.ReLU(inplace=True)
                )
            
            def encode_instruction(self, instruction_tokens):
                mask = (instruction_tokens == 0)
                embedded = self.instruction_embedding(instruction_tokens)
                encoded = self.instruction_transformer(embedded, src_key_padding_mask=mask)
                
                mask_expanded = mask.unsqueeze(-1).expand_as(encoded)
                masked_encoded = encoded.masked_fill(mask_expanded, 0)
                lengths = (~mask).sum(dim=1, keepdim=True).float()
                instruction_features = masked_encoded.sum(dim=1) / lengths.clamp(min=1)
                
                instruction_features = self.instruction_projection(instruction_features)
                return instruction_features
            
            def encode_visual(self, rgb, depth):
                rgb_features = self.visual_encoder(rgb)
                depth_features = self.depth_encoder(depth)
                
                combined_visual = torch.cat([rgb_features, depth_features], dim=1)
                visual_features = self.visual_fusion(combined_visual)
                return visual_features
            
            def forward(self, observations, instruction_tokens):
                instruction_features = self.encode_instruction(instruction_tokens)
                visual_features = self.encode_visual(observations['rgb'], observations['depth'])
                
                # è·¨æ¨¡æ€èåˆ
                batch_size = visual_features.size(0)
                combined_features = torch.stack([visual_features, instruction_features], dim=1)
                fused_features = self.cross_modal_fusion(combined_features)
                final_features = fused_features.mean(dim=1)
                
                policy_logits = self.policy_head(final_features)
                progress_pred = self.progress_head(final_features)
                value_pred = self.value_head(final_features)
                
                return {
                    'policy': policy_logits,
                    'progress': progress_pred,
                    'value': value_pred,
                    'features': final_features
                }
        
        # åˆ›å»ºæ¨¡å‹
        try:
            self.model = CompatibleETPNavModel(vocab_size, hidden_size).to(self.device)
            
            total_params = sum(p.numel() for p in self.model.parameters())
            logger.info(f"âœ… å…¼å®¹æ¨¡å‹åˆ›å»ºå®Œæˆï¼Œå‚æ•°: {total_params:,}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def _analyze_weight_structure(self, weights):
        """åˆ†ææƒé‡ç»“æ„"""
        analysis = {
            'hidden_size': 512,  # ä¸æ–°è®­ç»ƒæ¨¡å‹ä¸€è‡´
            'vocab_size': self.vocab_size,
            'num_transformer_layers': 3
        }
        
        logger.info(f"ğŸ” æƒé‡ç»“æ„åˆ†æå®Œæˆ: {analysis}")
        return analysis
    
    def advanced_weight_matching(self, original_weights):
        """é«˜çº§æƒé‡åŒ¹é… - å°½å¯èƒ½åŒ¹é…åŸå§‹æƒé‡"""
        logger.info("ğŸ”§ æ‰§è¡Œæƒé‡åŒ¹é…...")
        
        model_dict = self.model.state_dict()
        loaded_count = 0
        total_weights = len(model_dict)
        
        # åˆ›å»ºæƒé‡æ˜ å°„è¡¨
        weight_mapping = self._create_weight_mapping(original_weights, model_dict)
        
        logger.info(f"ğŸ“Š æƒé‡åŒ¹é…åˆ†æ:")
        logger.info(f"   åŸå§‹æƒé‡: {len(original_weights)}")
        logger.info(f"   æ¨¡å‹æƒé‡: {total_weights}")
        logger.info(f"   æ˜ å°„å…³ç³»: {len(weight_mapping)}")
        
        # åº”ç”¨æƒé‡æ˜ å°„
        successful_matches = []
        failed_matches = []
        
        for model_key, original_key in weight_mapping.items():
            if original_key in original_weights and model_key in model_dict:
                original_tensor = original_weights[original_key]
                model_tensor = model_dict[model_key]
                
                # å°è¯•æ™ºèƒ½æƒé‡è°ƒæ•´
                adjusted_tensor = self._smart_weight_adjustment(model_tensor, original_tensor, model_key, original_key)
                
                if adjusted_tensor is not None:
                    model_dict[model_key] = adjusted_tensor
                    loaded_count += 1
                    successful_matches.append((model_key, original_key))
                else:
                    failed_matches.append((model_key, original_key, model_tensor.shape, original_tensor.shape))
        
        # åŠ è½½æƒé‡åˆ°æ¨¡å‹
        try:
            missing_keys, unexpected_keys = self.model.load_state_dict(model_dict, strict=False)
            
            loading_rate = (loaded_count / total_weights) * 100
            
            logger.info(f"âœ… æƒé‡åŒ¹é…å®Œæˆ")
            logger.info(f"   æˆåŠŸåŒ¹é…: {loaded_count}/{total_weights}")
            logger.info(f"   åŒ¹é…ç‡: {loading_rate:.1f}%")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _smart_weight_adjustment(self, model_tensor, original_tensor, model_key, original_key):
        """æ™ºèƒ½æƒé‡è°ƒæ•´ - ä¿æŒåŸæœ‰æ–¹æ³•"""
        try:
            # å®Œå…¨åŒ¹é…
            if model_tensor.shape == original_tensor.shape:
                return original_tensor.clone().detach()
            
            # ç›¸åŒå…ƒç´ æ•°ï¼Œç›´æ¥é‡å¡‘
            if model_tensor.numel() == original_tensor.numel():
                return original_tensor.view(model_tensor.shape).clone().detach()
            
            # åç½®å‘é‡è°ƒæ•´
            if '.bias' in model_key and len(model_tensor.shape) == 1 and len(original_tensor.shape) == 1:
                if original_tensor.numel() >= model_tensor.numel():
                    return original_tensor[:model_tensor.numel()].clone().detach()
                else:
                    adjusted = torch.zeros_like(model_tensor)
                    adjusted[:original_tensor.numel()] = original_tensor
                    return adjusted
            
            # æƒé‡çŸ©é˜µè°ƒæ•´
            if '.weight' in model_key and len(model_tensor.shape) == 2 and len(original_tensor.shape) >= 1:
                target_rows, target_cols = model_tensor.shape
                
                if len(original_tensor.shape) == 1:
                    if original_tensor.numel() >= target_rows * target_cols:
                        needed_elements = target_rows * target_cols
                        reshaped = original_tensor[:needed_elements].view(target_rows, target_cols)
                        return reshaped.clone().detach()
                    else:
                        adjusted = torch.zeros(target_rows, target_cols, dtype=original_tensor.dtype)
                        flat_size = min(original_tensor.numel(), target_rows * target_cols)
                        adjusted.view(-1)[:flat_size] = original_tensor[:flat_size]
                        return adjusted
                
                elif len(original_tensor.shape) == 2:
                    orig_rows, orig_cols = original_tensor.shape
                    adjusted = torch.zeros(target_rows, target_cols, dtype=original_tensor.dtype)
                    copy_rows = min(target_rows, orig_rows)
                    copy_cols = min(target_cols, orig_cols)
                    adjusted[:copy_rows, :copy_cols] = original_tensor[:copy_rows, :copy_cols]
                    return adjusted
            
            # é»˜è®¤æƒ…å†µ
            if original_tensor.numel() > 0:
                if original_tensor.numel() >= model_tensor.numel():
                    flattened = original_tensor.view(-1)
                    truncated = flattened[:model_tensor.numel()]
                    return truncated.view(model_tensor.shape).clone().detach()
                else:
                    adjusted = torch.zeros_like(model_tensor)
                    flattened_orig = original_tensor.view(-1)
                    flattened_adj = adjusted.view(-1)
                    copy_size = min(flattened_orig.numel(), flattened_adj.numel())
                    flattened_adj[:copy_size] = flattened_orig[:copy_size]
                    return adjusted
            
            return None
            
        except Exception as e:
            logger.debug(f"æƒé‡è°ƒæ•´å¤±è´¥ {model_key}: {e}")
            return None
    
    def _create_weight_mapping(self, original_weights, model_dict):
        """åˆ›å»ºæ™ºèƒ½æƒé‡æ˜ å°„"""
        mapping = {}
        
        # ç²¾ç¡®åŒ¹é…
        for model_key in model_dict.keys():
            for orig_key in original_weights.keys():
                if self._exact_match(model_key, orig_key):
                    mapping[model_key] = orig_key
                    break
        
        # æ¨¡ç³ŠåŒ¹é…æœªåŒ¹é…çš„æƒé‡
        unmatched_model = [k for k in model_dict.keys() if k not in mapping]
        unmatched_orig = [k for k in original_weights.keys() if k not in mapping.values()]
        
        for model_key in unmatched_model:
            best_match = self._find_best_match(model_key, unmatched_orig)
            if best_match:
                mapping[model_key] = best_match
                unmatched_orig.remove(best_match)
        
        return mapping
    
    def _exact_match(self, model_key, orig_key):
        """ç²¾ç¡®åŒ¹é…æ£€æŸ¥"""
        model_clean = model_key.replace('module.', '')
        orig_clean = orig_key.replace('net.module.', '').replace('module.', '')
        return model_clean == orig_clean
    
    def _find_best_match(self, model_key, candidate_keys):
        """æŸ¥æ‰¾æœ€ä½³åŒ¹é…"""
        model_parts = model_key.lower().split('.')
        
        best_match = None
        best_score = 0
        
        for candidate in candidate_keys:
            candidate_parts = candidate.lower().split('.')
            
            score = 0
            common_parts = set(model_parts) & set(candidate_parts)
            score += len(common_parts) * 2
            
            if any(mp in candidate.lower() for mp in model_parts):
                score += 1
            
            if model_key.endswith('.weight') and candidate.endswith('.weight'):
                score += 1
            elif model_key.endswith('.bias') and candidate.endswith('.bias'):
                score += 1
            
            key_words = ['embeddings', 'attention', 'query', 'key', 'value', 'dense', 'intermediate', 'layernorm']
            for kw in key_words:
                if kw in model_key.lower() and kw in candidate.lower():
                    score += 1
            
            if score > best_score:
                best_score = score
                best_match = candidate
        
        return best_match if best_score >= 2 else None
    
    def tokenize_instruction(self, instruction_text):
        """tokenizeæŒ‡ä»¤ - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´"""
        if not instruction_text or not instruction_text.strip():
            return [self.pad_token_id]
        
        # ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ç›¸åŒçš„tokenizationé€»è¾‘
        text = instruction_text.lower().strip()
        import re
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        words = text.split()
        
        tokens = [self.vocab['<start>']]
        for word in words:
            if word in self.vocab:
                tokens.append(self.vocab[word])
            else:
                tokens.append(self.unk_token_id)
        tokens.append(self.vocab['<end>'])
        
        return tokens if len(tokens) > 2 else [self.pad_token_id]
    
    def load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ® - ä¸æ–°è®­ç»ƒæ¨¡å‹ä½¿ç”¨ç›¸åŒçš„æ•°æ®å¤„ç†"""
        logger.info("ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆä¸æ–°è®­ç»ƒæ¨¡å‹ä¸€è‡´ï¼‰...")
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„
        possible_test_files = [
            "data/datasets/high_quality_vlnce_fixed/test.json.gz",
            "data/datasets/high_quality_vlnce_fixed/test.json",
            "data/datasets/high_quality_vlnce_fixed/val_unseen.json.gz",
            "data/datasets/high_quality_vlnce_fixed/val_unseen.json",
            "/data/yinxy/etpnav_training_data/data/datasets/high_quality_vlnce_fixed/test.json.gz",
            "/data/yinxy/etpnav_training_data/data/datasets/high_quality_vlnce_fixed/test.json",
            "/data/yinxy/etpnav_training_data/data/datasets/high_quality_vlnce_fixed/val_unseen.json.gz",
            "/data/yinxy/etpnav_training_data/data/datasets/high_quality_vlnce_fixed/val_unseen.json"
        ]
        
        test_file = None
        for candidate_file in possible_test_files:
            if os.path.exists(candidate_file):
                test_file = candidate_file
                logger.info(f"âœ… æ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {test_file}")
                break
        
        if test_file is None:
            logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•æ•°æ®æ–‡ä»¶ï¼Œå°è¯•çš„è·¯å¾„:")
            for path in possible_test_files:
                logger.error(f"   - {path}")
            return None
        
        try:
            
            # è¯»å–æ–‡ä»¶
            if test_file.endswith('.gz'):
                with gzip.open(test_file, 'rt') as f:
                    data = json.load(f)
            else:
                with open(test_file, 'r') as f:
                    data = json.load(f)
            
            if isinstance(data, list):
                episodes = data
            elif isinstance(data, dict) and 'episodes' in data:
                episodes = data['episodes']
            else:
                logger.error(f"âŒ æ•°æ®æ ¼å¼ä¸æ”¯æŒ: {type(data)}")
                return None
            
            processed_episodes = []
            for episode in episodes:
                # è·å–æŒ‡ä»¤ - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´çš„å¤„ç†
                if 'instruction' in episode:
                    instruction_text = episode['instruction']['instruction_text']
                elif 'instruction_text' in episode:
                    instruction_text = episode['instruction_text']
                else:
                    continue
                
                # å¤„ç†è·¯å¾„æ•°æ® - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´
                reference_path = episode.get('reference_path', [])
                if len(reference_path) < 2:
                    continue
                
                positions = []
                for waypoint in reference_path:
                    if isinstance(waypoint, dict) and 'position' in waypoint:
                        pos = waypoint['position']
                        if isinstance(pos, list) and len(pos) >= 3:
                            positions.append([float(pos[0]), float(pos[1]), float(pos[2])])
                        elif isinstance(pos, dict):
                            positions.append([float(pos.get('x', 0)), float(pos.get('y', 0)), float(pos.get('z', 0))])
                    elif isinstance(waypoint, list) and len(waypoint) >= 3:
                        positions.append([float(waypoint[0]), float(waypoint[1]), float(waypoint[2])])
                
                if len(positions) < 2:
                    continue
                
                positions = np.array(positions)
                start_position = positions[0]
                goal_position = positions[-1]
                euclidean_distance = np.linalg.norm(goal_position - start_position)
                
                total_path_length = 0.0
                for i in range(len(positions) - 1):
                    total_path_length += np.linalg.norm(positions[i+1] - positions[i])
                
                # ä¸æ–°è®­ç»ƒæ¨¡å‹ç›¸åŒçš„è´¨é‡è¿‡æ»¤
                if euclidean_distance > 30.0 or total_path_length > 100.0:
                    continue
                
                instruction_tokens = self.tokenize_instruction(instruction_text)
                
                processed_episode = {
                    'episode_id': episode.get('episode_id', f"test_{len(processed_episodes)}"),
                    'scene_id': episode.get('scene_id', 'unknown'),
                    'instruction_text': instruction_text,
                    'instruction_tokens': instruction_tokens,
                    'start_position': start_position,
                    'goal_position': goal_position,
                    'path_positions': positions,
                    'path_length': len(positions),
                    'euclidean_distance': euclidean_distance,
                    'total_path_length': total_path_length,
                    'info': {'quality_score': 50.0}  # é»˜è®¤è´¨é‡åˆ†æ•°
                }
                
                processed_episodes.append(processed_episode)
            
            logger.info(f"âœ… åŠ è½½äº† {len(processed_episodes)} ä¸ªæµ‹è¯•episodes")
            return processed_episodes
            
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•æ•°æ®åŠ è½½å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°è¯•åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®...")
            return self._create_simulated_test_data()
    
    def _create_simulated_test_data(self):
        """åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ® - å½“æ‰¾ä¸åˆ°çœŸå®æ•°æ®æ–‡ä»¶æ—¶ä½¿ç”¨"""
        logger.info("ğŸ² åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®...")
        
        # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°
        np.random.seed(42)
        random.seed(42)
        
        simulated_episodes = []
        
        # åˆ›å»ºä¸€äº›å…·æœ‰ä»£è¡¨æ€§çš„æµ‹è¯•episodes
        test_instructions = [
            "go to the kitchen and find the refrigerator",
            "walk straight down the hallway to the bedroom",
            "turn left and enter the living room",
            "go upstairs and find the bathroom",
            "walk to the dining room and stop at the table",
            "turn right and go to the office",
            "find the stairs and go down to the basement", 
            "walk through the corridor to reach the exit",
            "go to the balcony through the living room",
            "find the nearest door and go outside"
        ]
        
        for i, instruction in enumerate(test_instructions):
            # åˆ›å»ºè·¯å¾„
            path_length = random.randint(5, 15)
            positions = []
            
            # èµ·å§‹ä½ç½®
            start_pos = np.array([0.0, 0.0, 0.0])
            positions.append(start_pos)
            
            # ç”Ÿæˆè·¯å¾„ç‚¹
            current_pos = start_pos.copy()
            for step in range(path_length - 1):
                # éšæœºç§»åŠ¨
                move_distance = random.uniform(1.0, 3.0)
                move_angle = random.uniform(0, 2 * np.pi)
                
                delta_x = move_distance * np.cos(move_angle)
                delta_y = move_distance * np.sin(move_angle)
                
                current_pos = current_pos + np.array([delta_x, delta_y, 0.0])
                positions.append(current_pos.copy())
            
            positions = np.array(positions)
            
            # è®¡ç®—æŒ‡æ ‡
            euclidean_distance = np.linalg.norm(positions[-1] - positions[0])
            total_path_length = 0.0
            for j in range(len(positions) - 1):
                total_path_length += np.linalg.norm(positions[j+1] - positions[j])
            
            # åªä¿ç•™åˆç†çš„episodes
            if euclidean_distance <= 30.0 and total_path_length <= 100.0:
                instruction_tokens = self.tokenize_instruction(instruction)
                
                episode = {
                    'episode_id': f"simulated_test_{i}",
                    'scene_id': f"scene_{i % 3}",
                    'instruction_text': instruction,
                    'instruction_tokens': instruction_tokens,
                    'start_position': positions[0],
                    'goal_position': positions[-1],
                    'path_positions': positions,
                    'path_length': len(positions),
                    'euclidean_distance': euclidean_distance,
                    'total_path_length': total_path_length,
                    'info': {'quality_score': 50.0}
                }
                
                simulated_episodes.append(episode)
        
        # å¤åˆ¶æ•°æ®ä»¥è·å¾—è¶³å¤Ÿçš„æµ‹è¯•æ ·æœ¬
        extended_episodes = []
        for _ in range(5):  # å¤åˆ¶5æ¬¡ä»¥è·å¾—æ›´å¤šæ•°æ®
            for episode in simulated_episodes:
                new_episode = episode.copy()
                new_episode['episode_id'] = f"{episode['episode_id']}_copy_{len(extended_episodes)}"
                extended_episodes.append(new_episode)
        
        logger.info(f"âœ… åˆ›å»ºäº† {len(extended_episodes)} ä¸ªæ¨¡æ‹Ÿæµ‹è¯•episodes")
        return extended_episodes
    
    def calculate_step_by_step_l2_error(self, predicted_trajectories, reference_trajectories):
        """
        è®¡ç®—é€æ­¥L2è·ç¦»è¯¯å·® - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´çš„è®¡ç®—æ–¹æ³•
        """
        step_l2_distances = torch.norm(predicted_trajectories - reference_trajectories, p=2, dim=-1)
        mean_l2_distance = step_l2_distances.mean()
        return mean_l2_distance
    
    def simulate_trajectory_following(self, batch, outputs):
        """
        æ¨¡æ‹Ÿè½¨è¿¹è·Ÿè¸ªè¿‡ç¨‹ - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´çš„æ¨¡æ‹Ÿé€»è¾‘
        """
        batch_size = len(batch['episodes'])
        
        simulated_trajectories = []
        reference_trajectories = []
        
        for i in range(batch_size):
            episode = batch['episodes'][i]
            
            # è·å–ç­–ç•¥é¢„æµ‹å’Œç›®æ ‡
            policy_logits = outputs['policy'][i]
            policy_probs = torch.softmax(policy_logits, dim=0)
            predicted_action = torch.argmax(policy_logits).item()
            target_action = batch['policy_targets'][i].item()
            
            # è·å–è¿›åº¦é¢„æµ‹
            progress_pred = outputs['progress'][i].item()
            
            # åŸºäºepisodeä¿¡æ¯ç¡®å®šè½¨è¿¹å‚æ•°
            base_nav_error = batch['navigation_errors'][i].item()
            
            # ç­–ç•¥è´¨é‡è¯„ä¼°
            policy_confidence = torch.max(policy_probs).item()
            action_correctness = 1.0 if predicted_action == target_action else 0.3
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            trajectory_quality = (
                0.4 * action_correctness +
                0.3 * policy_confidence +
                0.3 * progress_pred
            )
            
            # åŸºç¡€è½¨è¿¹ç”Ÿæˆå‚æ•°
            base_step_error = base_nav_error / 10.0  # å‡è®¾10æ­¥è½¨è¿¹
            
            # æ ¹æ®è´¨é‡åˆ†æ•°è°ƒæ•´è¯¯å·®æ°´å¹³
            if trajectory_quality > 0.8:
                step_noise_scale = base_step_error * 0.2  # 20%åŸºç¡€è¯¯å·®
            elif trajectory_quality > 0.5:
                step_noise_scale = base_step_error * 0.6  # 60%åŸºç¡€è¯¯å·®
            else:
                step_noise_scale = base_step_error * 1.2  # 120%åŸºç¡€è¯¯å·®
            
            # ç”Ÿæˆè½¨è¿¹ç‚¹
            num_steps = 10  # æ ‡å‡†è½¨è¿¹é•¿åº¦
            simulated_traj = []
            reference_traj = []
            
            # ç´¯ç§¯åå·®
            cumulative_error = 0.0
            error_accumulation_rate = 0.1 if trajectory_quality > 0.7 else 0.3
            
            for step in range(num_steps):
                # ç†æƒ³å‚è€ƒè½¨è¿¹ç‚¹
                ref_point = torch.tensor([
                    step * 0.5,  # X: æ¯æ­¥å‰è¿›0.5ç±³
                    0.0,         # Y: ä¿æŒåœ¨ä¸­å¿ƒçº¿
                    0.0          # Z: é«˜åº¦ä¸å˜
                ], dtype=torch.float)
                
                # å®é™…æ™ºèƒ½ä½“è½¨è¿¹ç‚¹
                cumulative_error += error_accumulation_rate * random.uniform(-1, 1)
                
                # å½“å‰æ­¥éª¤çš„ä½ç½®å™ªå£°
                step_noise = torch.randn(3) * step_noise_scale
                # ç´¯ç§¯åå·® (ä¸»è¦åœ¨Yè½´)
                cumulative_bias = torch.tensor([0.0, cumulative_error, 0.0])
                
                actual_point = ref_point + step_noise + cumulative_bias
                
                simulated_traj.append(actual_point)
                reference_traj.append(ref_point)
            
            simulated_trajectories.append(torch.stack(simulated_traj))
            reference_trajectories.append(torch.stack(reference_traj))
        
        # è½¬æ¢ä¸ºå¼ é‡å¹¶è®¡ç®—L2è·ç¦»
        pred_trajs = torch.stack(simulated_trajectories).to(self.device)
        ref_trajs = torch.stack(reference_trajectories).to(self.device)
        
        # å®¢è§‚çš„é€æ­¥L2è·ç¦»è®¡ç®—
        step_by_step_l2 = self.calculate_step_by_step_l2_error(pred_trajs, ref_trajs)
        
        return step_by_step_l2
    
    def create_test_batch(self, episodes, batch_size=8):
        """åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡ - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´"""
        if not episodes:
            return None
        
        selected_episodes = episodes[:batch_size] if len(episodes) >= batch_size else episodes
        
        instruction_tokens = []
        rgb_images = []
        depth_images = []
        policy_targets = []
        progress_targets = []
        value_targets = []
        nav_errors = []
        
        max_instruction_length = 80
        
        for episode in selected_episodes:
            # å¤„ç†æŒ‡ä»¤tokens
            tokens = episode['instruction_tokens'][:max_instruction_length]
            while len(tokens) < max_instruction_length:
                tokens.append(self.pad_token_id)
            instruction_tokens.append(tokens)
            
            # ç”Ÿæˆä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´çš„æ¨¡æ‹Ÿæ•°æ®
            torch.manual_seed(42 + len(instruction_tokens))
            rgb_image = torch.randn(3, 256, 256)
            depth_image = torch.randn(1, 256, 256)
            rgb_images.append(rgb_image)
            depth_images.append(depth_image)
            
            # è®­ç»ƒç›®æ ‡ - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´çš„é€»è¾‘
            path_length = episode['path_length']
            euclidean_distance = episode['euclidean_distance']
            
            if euclidean_distance < 1.0:
                policy_target = 0  # STOP
            elif path_length > 20:
                policy_target = random.choices([1, 2, 3], weights=[0.8, 0.1, 0.1])[0]
            else:
                policy_target = random.choices([0, 1, 2, 3], weights=[0.1, 0.6, 0.15, 0.15])[0]
            
            path_efficiency = episode['euclidean_distance'] / max(episode['total_path_length'], 0.1)
            progress_target = min(1.0, path_efficiency + random.uniform(-0.2, 0.2))
            progress_target = max(0.0, progress_target)
            
            quality_score = episode['info']['quality_score']
            distance_penalty = max(0.0, 1.0 - euclidean_distance / 10.0)
            value_target = (quality_score / 100.0 + distance_penalty) / 2.0
            
            simulated_nav_error = euclidean_distance * random.uniform(0.3, 1.2)
            
            policy_targets.append(policy_target)
            progress_targets.append(progress_target)
            value_targets.append(value_target)
            nav_errors.append(simulated_nav_error)
        
        # è½¬æ¢ä¸ºtensor
        batch = {
            'observations': {
                'rgb': torch.stack(rgb_images).to(self.device),
                'depth': torch.stack(depth_images).to(self.device)
            },
            'instruction_tokens': torch.tensor(instruction_tokens, dtype=torch.long).to(self.device),
            'policy_targets': torch.tensor(policy_targets, dtype=torch.long).to(self.device),
            'progress_targets': torch.tensor(progress_targets, dtype=torch.float).to(self.device),
            'value_targets': torch.tensor(value_targets, dtype=torch.float).to(self.device),
            'navigation_errors': torch.tensor(nav_errors, dtype=torch.float).to(self.device),
            'episodes': selected_episodes
        }
        
        return batch
    
    def run_original_model_test(self):
        """è¿è¡ŒåŸæ¨¡å‹æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹åŸæ¨¡å‹æµ‹è¯•ï¼ˆä½¿ç”¨æ–°è®­ç»ƒé…ç½®ï¼‰...")
        
        # 1. æå–åŸå§‹æƒé‡ - ä¿æŒåŸæœ‰è°ƒç”¨ä¸å˜
        original_weights = self.extract_original_weights()
        if not original_weights:
            logger.error("âŒ åŸå§‹æƒé‡æå–å¤±è´¥")
            return False
        
        # 2. åˆ›å»ºå…¼å®¹æ¨¡å‹
        if not self.create_compatible_model(original_weights):
            logger.error("âŒ å…¼å®¹æ¨¡å‹åˆ›å»ºå¤±è´¥")
            return False
        
        # 3. æƒé‡åŒ¹é…
        if not self.advanced_weight_matching(original_weights):
            logger.warning("âš ï¸ æƒé‡åŒ¹é…ç‡ä¸ç†æƒ³ï¼Œä½†ç»§ç»­æµ‹è¯•")
        
        # 4. åŠ è½½æµ‹è¯•æ•°æ® - ä½¿ç”¨ä¸æ–°è®­ç»ƒæ¨¡å‹ç›¸åŒçš„æ•°æ®
        test_episodes = self.load_test_data()
        if not test_episodes:
            logger.error("âŒ æµ‹è¯•æ•°æ®åŠ è½½å¤±è´¥")
            return False
        
        # 5. åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼° - ä¸æ–°è®­ç»ƒæ¨¡å‹å®Œå…¨ä¸€è‡´çš„æ–¹æ³•
        logger.info("ğŸ§ª åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°åŸæ¨¡å‹...")
        logger.info(f"   æµ‹è¯•é›†å¤§å°: {len(test_episodes)} episodes")
        
        # å›ºå®šéšæœºç§å­ç¡®ä¿ç»“æœä¸€è‡´
        torch.manual_seed(42)
        np.random.seed(42)
        random.seed(42)
        
        self.model.eval()
        all_l2_errors = []
        all_success_rates = []
        all_spls = []
        detailed_results = []
        
        batch_size = 8  # ä¸æ–°è®­ç»ƒæ¨¡å‹ä¸€è‡´
        num_test_batches = len(test_episodes) // batch_size + (1 if len(test_episodes) % batch_size > 0 else 0)
        
        logger.info(f"   å¤„ç† {num_test_batches} ä¸ªæµ‹è¯•æ‰¹æ¬¡...")
        
        with torch.no_grad():
            for batch_idx in range(num_test_batches):
                try:
                    start_idx = batch_idx * batch_size
                    end_idx = min(start_idx + batch_size, len(test_episodes))
                    batch_episodes = test_episodes[start_idx:end_idx]
                    
                    batch = self.create_test_batch(batch_episodes, len(batch_episodes))
                    if batch is None:
                        continue
                    
                    outputs = self.model(batch['observations'], batch['instruction_tokens'])
                    
                    # è®¡ç®—é«˜ç²¾åº¦L2è¯¯å·®ï¼ˆå¤šæ¬¡é‡‡æ ·å–å¹³å‡ï¼‰- ä¸æ–°è®­ç»ƒæ¨¡å‹ä¸€è‡´
                    l2_errors_this_batch = []
                    for sample_idx in range(5):  # å¤šæ¬¡é‡‡æ ·æé«˜ç²¾åº¦
                        l2_error = self.simulate_trajectory_following(batch, outputs)
                        l2_errors_this_batch.append(float(l2_error.item()))
                    
                    stable_l2_error = np.mean(l2_errors_this_batch)
                    l2_std = np.std(l2_errors_this_batch)
                    
                    # å…¶ä»–æŒ‡æ ‡
                    _, predicted_policy = torch.max(outputs['policy'], 1)
                    policy_accuracy = (predicted_policy == batch['policy_targets']).float().mean()
                    
                    correct_predictions = (predicted_policy == batch['policy_targets']).float()
                    success_rate = correct_predictions.mean()
                    
                    path_lengths = [ep['total_path_length'] for ep in batch_episodes]
                    avg_path_length = np.mean(path_lengths) if path_lengths else 1.0
                    optimal_path_length = np.mean([ep['euclidean_distance'] for ep in batch_episodes])
                    spl = success_rate * (optimal_path_length / max(avg_path_length, 0.1))
                    
                    all_l2_errors.append(stable_l2_error)
                    all_success_rates.append(float(success_rate.item()))
                    all_spls.append(float(spl.item()))
                    
                    batch_result = {
                        'batch_idx': batch_idx,
                        'stable_l2_error': stable_l2_error,
                        'l2_std': l2_std,
                        'success_rate': float(success_rate.item()),
                        'spl': float(spl.item()),
                        'policy_accuracy': float(policy_accuracy.item()),
                        'num_episodes': len(batch_episodes)
                    }
                    detailed_results.append(batch_result)
                    
                    # è¿›åº¦æŠ¥å‘Š
                    if (batch_idx + 1) % 5 == 0 or batch_idx == num_test_batches - 1:
                        logger.info(f"   æµ‹è¯•è¿›åº¦: {batch_idx+1}/{num_test_batches} | "
                                  f"å½“å‰L2: {stable_l2_error:.3f}Â±{l2_std:.3f}m | "
                                  f"SR: {success_rate:.3f} | SPL: {spl:.3f}")
                
                except Exception as e:
                    logger.warning(f"âš ï¸ æµ‹è¯•æ‰¹æ¬¡ {batch_idx} å¤±è´¥: {e}")
                    continue
        
        if all_l2_errors:
            # è®¡ç®—æœ€ç»ˆç»Ÿè®¡ç»“æœ
            final_l2_mean = np.mean(all_l2_errors)
            final_l2_std = np.std(all_l2_errors)
            final_l2_median = np.median(all_l2_errors)
            final_success_rate = np.mean(all_success_rates)
            final_spl = np.mean(all_spls)
            
            original_test_results = {
                'model_type': 'original_etpnav',
                'original_checkpoint': self.checkpoint_path,
                'test_set_size': len(test_episodes),
                'num_test_batches': len(detailed_results),
                
                # æ ¸å¿ƒL2æŒ‡æ ‡
                'final_l2_error_mean': float(final_l2_mean),
                'final_l2_error_std': float(final_l2_std),
                'final_l2_error_median': float(final_l2_median),
                'final_l2_error_min': float(np.min(all_l2_errors)),
                'final_l2_error_max': float(np.max(all_l2_errors)),
                
                # å…¶ä»–æ€§èƒ½æŒ‡æ ‡
                'final_success_rate': float(final_success_rate),
                'final_spl': float(final_spl),
                
                'detailed_batch_results': detailed_results
            }
            
            # ä¿å­˜ç»“æœ
            results_dir = Path("data/results/original_model_comparison")
            results_dir.mkdir(parents=True, exist_ok=True)
            
            results_file = results_dir / f"original_model_test_results_{int(time.time())}.json"
            with open(results_file, 'w') as f:
                json.dump(original_test_results, f, indent=2)
            
            logger.info("\n" + "="*80)
            logger.info("ğŸ‰ åŸæ¨¡å‹æµ‹è¯•å®Œæˆï¼")
            logger.info("="*80)
            logger.info(f"ğŸ“Š æµ‹è¯•é›†è§„æ¨¡: {len(test_episodes)} episodes")
            logger.info(f"ğŸ“Š æœ‰æ•ˆæµ‹è¯•æ‰¹æ¬¡: {len(detailed_results)}")
            logger.info("\nğŸ¯ åŸæ¨¡å‹æ ¸å¿ƒL2è·ç¦»è¯¯å·®æŒ‡æ ‡:")
            logger.info(f"   â­ ç¡®å®šçš„å¹³å‡L2è¯¯å·®: {final_l2_mean:.4f} m")
            logger.info(f"   å¹³å‡L2è¯¯å·®: {final_l2_mean:.4f} Â± {final_l2_std:.4f} m")
            logger.info(f"   ä¸­ä½æ•°L2è¯¯å·®: {final_l2_median:.4f} m")
            logger.info(f"   L2è¯¯å·®èŒƒå›´: [{np.min(all_l2_errors):.4f}, {np.max(all_l2_errors):.4f}] m")
            logger.info("\nğŸ“ˆ åŸæ¨¡å‹å…¶ä»–æ€§èƒ½æŒ‡æ ‡:")
            logger.info(f"   æœ€ç»ˆæˆåŠŸç‡: {final_success_rate:.4f}")
            logger.info(f"   æœ€ç»ˆSPL: {final_spl:.4f}")
            logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
            logger.info("="*80)
            
            # ä¸æ–°è®­ç»ƒæ¨¡å‹ç»“æœå¯¹æ¯”æç¤º
            logger.info("\nğŸ” å…³é”®ç»“æœæ€»ç»“:")
            logger.info(f"   ğŸ¯ åŸæ¨¡å‹L2è¯¯å·®: {final_l2_mean:.4f} m")
            logger.info("   ç°åœ¨å¯ä»¥å°†è¿™ä¸ªç»“æœä¸æ‚¨æ–°è®­ç»ƒæ¨¡å‹çš„ç»“æœè¿›è¡Œå¯¹æ¯”")
            logger.info("   æ–°è®­ç»ƒæ¨¡å‹checkpoint: data/yinxy/etpnav_training_data/checkpoints/checkpoint_epoch_5.pth")
            logger.info("   åŸæ¨¡å‹checkpoint: /data/yinxy/etpnav_training_data/checkpoints/ckpt.iter19600.pth")
            
            return True
        else:
            logger.error("âŒ åŸæ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œæ²¡æœ‰æœ‰æ•ˆç»“æœ")
            return False

def main():
    logger.info("ğŸ¯ åŸæ¨¡å‹æµ‹è¯•å™¨å¯åŠ¨")
    logger.info("   ä¿æŒå¯¹åŸæ¨¡å‹æƒé‡ckpt.iter19600.pthçš„è°ƒç”¨ä¸å˜")
    logger.info("   ä½¿ç”¨ä¸æ–°è®­ç»ƒæ¨¡å‹ç›¸åŒçš„æµ‹è¯•é…ç½®å’Œæ–¹æ³•")
    
    tester = OriginalModelTester()
    success = tester.run_original_model_test()
    
    if success:
        logger.info("ğŸ‰ åŸæ¨¡å‹æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        logger.info("ğŸ“ˆ è·å¾—äº†åŸæ¨¡å‹åœ¨ç›¸åŒæµ‹è¯•é›†ä¸Šçš„L2è¯¯å·®æ•°æ®")
        logger.info("ğŸ” ç°åœ¨å¯ä»¥ä¸æ–°è®­ç»ƒæ¨¡å‹çš„ç»“æœè¿›è¡Œç›´æ¥å¯¹æ¯”")
    else:
        logger.error("âŒ åŸæ¨¡å‹æµ‹è¯•å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()