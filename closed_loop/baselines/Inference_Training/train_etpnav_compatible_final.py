import sys
import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
import logging
import argparse
import numpy as np
from pathlib import Path
import gzip
import time
import random
from collections import defaultdict
import math

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ETPNavTrainer:
    """ETPNavè®­ç»ƒå™¨ - ä¸“æ³¨äºcheckpointä¿å­˜å’ŒL2æŒ‡æ ‡è®¡ç®—"""
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() and config.get('use_gpu', False) else 'cpu')
        
        # ä½¿ç”¨æŒ‡å®šçš„checkpointç›®å½•
        self.checkpoint_dir = Path("/data/yinxy/etpnav_training_data/checkpoints")
        self.results_dir = Path("/data/yinxy/etpnav_training_data/results")
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ğŸ¯ ETPNavè®­ç»ƒå™¨")
        logger.info(f"   è®¾å¤‡: {self.device}")
        logger.info(f"   Checkpointç›®å½•: {self.checkpoint_dir}")
        logger.info(f"   ç»“æœç›®å½•: {self.results_dir}")
        
        # å›ºå®šéšæœºç§å­ç¡®ä¿è®­ç»ƒç»“æœå¯å¤ç°
        torch.manual_seed(42)
        np.random.seed(42)
        random.seed(42)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(42)
            torch.cuda.manual_seed_all(42)
        
        logger.info("ğŸ² éšæœºç§å­å·²å›ºå®šä¸º42ï¼Œç¡®ä¿è®­ç»ƒå¯å¤ç°")
        
        self.best_metrics = {
            'val_seen_spl': 0.0,
            'val_unseen_spl': 0.0,
            'val_seen_sr': 0.0,
            'val_unseen_sr': 0.0,
            'val_seen_l2_error': float('inf'),
            'val_unseen_l2_error': float('inf'),
            'best_epoch': 0
        }
        
        # æ„å»ºè¯æ±‡è¡¨
        self.build_vocabulary()
    
    def build_vocabulary(self):
        """æ„å»ºè¯æ±‡è¡¨"""
        logger.info("ğŸ“š æ„å»ºè¯æ±‡è¡¨...")
        
        special_tokens = ['<pad>', '<unk>', '<start>', '<end>', '<stop>']
        
        # VLN-CEå¸¸ç”¨è¯æ±‡
        navigation_words = [
            # åŠ¨ä½œè¯
            'go', 'walk', 'turn', 'move', 'head', 'proceed', 'continue', 'stop', 'reach',
            'enter', 'exit', 'follow', 'toward', 'forward', 'back', 'backward', 'take',
            'face', 'approach', 'cross', 'pass', 'climb', 'descend', 'ascend',
            
            # æ–¹å‘è¯  
            'left', 'right', 'straight', 'up', 'down', 'north', 'south', 'east', 'west',
            'ahead', 'behind', 'around', 'through', 'past', 'over', 'under',
            
            # ä½ç½®è¯
            'area', 'room', 'door', 'hall', 'corridor', 'stairs', 'building', 'floor',
            'wall', 'corner', 'entrance', 'exit', 'lobby', 'office', 'kitchen', 'bathroom',
            'bedroom', 'living', 'dining', 'hallway', 'staircase', 'balcony',
            
            # ç‰©å“è¯
            'table', 'chair', 'bed', 'desk', 'window', 'shelf', 'cabinet', 'counter',
            'couch', 'sofa', 'tv', 'television', 'lamp', 'door', 'plant', 'picture',
            'mirror', 'sink', 'toilet', 'shower', 'oven', 'refrigerator', 'fridge',
            
            # ä¿®é¥°è¯
            'next', 'nearest', 'closest', 'first', 'second', 'third', 'last', 'final',
            'large', 'small', 'big', 'wooden', 'white', 'black', 'brown', 'blue',
            'red', 'green', 'open', 'closed', 'round', 'square',
            
            # è¿æ¥è¯å’Œä»‹è¯
            'the', 'a', 'an', 'to', 'from', 'in', 'on', 'at', 'of', 'for', 'with',
            'and', 'or', 'then', 'until', 'when', 'where', 'there', 'here', 'this', 'that',
            'by', 'near', 'beside', 'between', 'above', 'below', 'inside', 'outside',
            
            # å…¶ä»–å¸¸ç”¨è¯
            'is', 'are', 'your', 'goal', 'located', 'find', 'see', 'look', 'will', 'should',
            'now', 'then', 'after', 'before', 'once', 'you', 'it', 'they', 'them'
        ]
        
        self.vocab = {token: idx for idx, token in enumerate(special_tokens + navigation_words)}
        self.vocab_size = len(self.vocab)
        self.pad_token_id = self.vocab['<pad>']
        self.unk_token_id = self.vocab['<unk>']
        self.stop_token_id = self.vocab['<stop>']
        
        logger.info(f"âœ… è¯æ±‡è¡¨æ„å»ºå®Œæˆï¼Œå¤§å°: {self.vocab_size}")
    
    def tokenize_instruction(self, instruction_text):
        """tokenizeæŒ‡ä»¤"""
        if not instruction_text or not instruction_text.strip():
            return [self.pad_token_id]
        
        # æ¸…ç†å’Œæ ‡å‡†åŒ–æ–‡æœ¬
        text = instruction_text.lower().strip()
        import re
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        words = text.split()
        
        tokens = [self.vocab['<start>']]
        for word in words:
            if word in self.vocab:
                tokens.append(self.vocab[word])
            else:
                tokens.append(self.unk_token_id)
        tokens.append(self.vocab['<end>'])
        
        return tokens if len(tokens) > 2 else [self.pad_token_id]
    
    def process_episode_data(self, episode):
        """å¤„ç†episodeæ•°æ®"""
        reference_path = episode.get('reference_path', [])
        if len(reference_path) < 2:
            return None
        
        # æå–è·¯å¾„ä½ç½®
        positions = []
        for waypoint in reference_path:
            if isinstance(waypoint, dict) and 'position' in waypoint:
                pos = waypoint['position']
                if isinstance(pos, list) and len(pos) >= 3:
                    positions.append([float(pos[0]), float(pos[1]), float(pos[2])])
                elif isinstance(pos, dict):
                    positions.append([float(pos.get('x', 0)), float(pos.get('y', 0)), float(pos.get('z', 0))])
            elif isinstance(waypoint, list) and len(waypoint) >= 3:
                positions.append([float(waypoint[0]), float(waypoint[1]), float(waypoint[2])])
        
        if len(positions) < 2:
            return None
        
        positions = np.array(positions)
        
        # èµ·å§‹å’Œç›®æ ‡ä½ç½®
        start_position = positions[0]
        goal_position = positions[-1]
        
        # å¤„ç†episodeä¸­çš„goalsä¿¡æ¯
        goals = episode.get('goals', [])
        if goals and len(goals) > 0:
            goal = goals[0]
            if isinstance(goal, dict) and 'position' in goal:
                goal_position = np.array([goal['position'][0], goal['position'][1], goal['position'][2]])
        
        # è®¡ç®—åŸºæœ¬æŒ‡æ ‡
        path_length = len(positions)
        euclidean_distance = np.linalg.norm(goal_position - start_position)
        
        # è®¡ç®—è·¯å¾„æ€»é•¿åº¦
        total_path_length = 0.0
        for i in range(len(positions) - 1):
            total_path_length += np.linalg.norm(positions[i+1] - positions[i])
        
        # è´¨é‡è¿‡æ»¤
        if euclidean_distance > 30.0 or total_path_length > 100.0 or path_length > 50:
            return None
        
        return {
            'start_position': start_position,
            'goal_position': goal_position,
            'path_positions': positions,
            'path_length': path_length,
            'euclidean_distance': euclidean_distance,
            'total_path_length': total_path_length
        }
    
    def load_datasets(self):
        """åŠ è½½æ•°æ®é›†"""
        logger.info("ğŸ“Š åŠ è½½æ•°æ®é›†...")
        
        dataset_files = {
            'train': "data/datasets/high_quality_vlnce_fixed/train.json.gz",
            'val_seen': "data/datasets/high_quality_vlnce_fixed/val_seen.json.gz", 
            'val_unseen': "data/datasets/high_quality_vlnce_fixed/val_unseen.json.gz",
            'test': "data/datasets/high_quality_vlnce_fixed/test.json.gz"  # æ·»åŠ æµ‹è¯•é›†
        }
        
        datasets = {}
        
        for split_name, file_path in dataset_files.items():
            try:
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä¸å¸¦.gzçš„ç‰ˆæœ¬
                if not os.path.exists(file_path):
                    alt_path = file_path.replace('.json.gz', '.json')
                    if os.path.exists(alt_path):
                        file_path = alt_path
                    else:
                        logger.warning(f"âš ï¸ {split_name} æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                        if split_name in ['train']:  # è®­ç»ƒé›†å¿…é¡»å­˜åœ¨
                            return None
                        else:
                            datasets[split_name] = []
                            continue
                
                # è¯»å–æ–‡ä»¶
                if file_path.endswith('.gz'):
                    with gzip.open(file_path, 'rt') as f:
                        data = json.load(f)
                else:
                    with open(file_path, 'r') as f:
                        data = json.load(f)
                
                if isinstance(data, list):
                    episodes = data
                elif isinstance(data, dict) and 'episodes' in data:
                    episodes = data['episodes']
                else:
                    logger.error(f"âŒ {split_name} æ•°æ®æ ¼å¼ä¸æ”¯æŒ: {type(data)}")
                    continue
                
                processed_episodes = []
                filtered_count = 0
                
                for episode in episodes:
                    # è·å–æŒ‡ä»¤
                    if 'instruction' in episode:
                        instruction_text = episode['instruction']['instruction_text']
                    elif 'instruction_text' in episode:
                        instruction_text = episode['instruction_text']
                    else:
                        filtered_count += 1
                        continue
                    
                    # å¤„ç†ä½ç½®æ•°æ®
                    processed_data = self.process_episode_data(episode)
                    if processed_data is None:
                        filtered_count += 1
                        continue
                    
                    # tokenizeæŒ‡ä»¤
                    instruction_tokens = self.tokenize_instruction(instruction_text)
                    
                    processed_episode = {
                        'episode_id': episode.get('episode_id', f"{split_name}_{len(processed_episodes)}"),
                        'scene_id': episode.get('scene_id', 'unknown'),
                        'instruction_text': instruction_text,
                        'instruction_tokens': instruction_tokens,
                        'reference_path': episode.get('reference_path', []),
                        
                        # æ ‡å‡†æ•°æ®
                        'start_position': processed_data['start_position'],
                        'goal_position': processed_data['goal_position'],
                        'path_positions': processed_data['path_positions'],
                        'path_length': processed_data['path_length'],
                        'euclidean_distance': processed_data['euclidean_distance'],
                        'total_path_length': processed_data['total_path_length'],
                        
                        'goals': episode.get('goals', []),
                        'info': episode.get('info', {'quality_score': 50.0}),
                        'split': split_name
                    }
                    
                    processed_episodes.append(processed_episode)
                
                datasets[split_name] = processed_episodes
                logger.info(f"âœ… {split_name}: {len(processed_episodes)} episodes (è¿‡æ»¤äº† {filtered_count} ä¸ª)")
                
            except Exception as e:
                logger.error(f"âŒ {split_name} åŠ è½½å¤±è´¥: {e}")
                if split_name == 'train':
                    return None
                else:
                    datasets[split_name] = []
        
        self.analyze_datasets(datasets)
        return datasets
    
    def analyze_datasets(self, datasets):
        """åˆ†ææ•°æ®é›†ç»Ÿè®¡"""
        logger.info("ğŸ” æ•°æ®é›†åˆ†æ:")
        
        for split_name, episodes in datasets.items():
            if not episodes:
                continue
            
            instruction_lengths = [len(ep['instruction_tokens']) for ep in episodes]
            path_lengths = [ep['path_length'] for ep in episodes]
            euclidean_distances = [ep['euclidean_distance'] for ep in episodes]
            total_path_lengths = [ep['total_path_length'] for ep in episodes]
            
            logger.info(f"  ğŸ“Š {split_name.upper()}:")
            logger.info(f"     Episodes: {len(episodes)}")
            logger.info(f"     æŒ‡ä»¤é•¿åº¦: å¹³å‡{np.mean(instruction_lengths):.1f}, èŒƒå›´{min(instruction_lengths)}-{max(instruction_lengths)}")
            logger.info(f"     è·¯å¾„é•¿åº¦: å¹³å‡{np.mean(path_lengths):.1f}, èŒƒå›´{min(path_lengths)}-{max(path_lengths)}")
            logger.info(f"     ğŸ“ æ¬§å‡ é‡Œå¾—è·ç¦»: å¹³å‡{np.mean(euclidean_distances):.2f}m, èŒƒå›´{min(euclidean_distances):.2f}-{max(euclidean_distances):.2f}m")
            logger.info(f"     ğŸš¶ è·¯å¾„æ€»é•¿åº¦: å¹³å‡{np.mean(total_path_lengths):.2f}m")
    
    def create_model(self):
        """åˆ›å»ºæ¨¡å‹æ¶æ„"""
        logger.info("ğŸ—ï¸ åˆ›å»ºETPNavæ¨¡å‹...")
        
        try:
            class ETPNavModel(nn.Module):
                def __init__(self, vocab_size, hidden_size=512):
                    super().__init__()
                    
                    self.hidden_size = hidden_size
                    self.vocab_size = vocab_size
                    
                    # æŒ‡ä»¤ç¼–ç å™¨
                    self.instruction_embedding = nn.Embedding(vocab_size, 256, padding_idx=0)
                    self.instruction_transformer = nn.TransformerEncoder(
                        nn.TransformerEncoderLayer(
                            d_model=256, 
                            nhead=8, 
                            dim_feedforward=512,
                            dropout=0.1,
                            batch_first=True
                        ),
                        num_layers=3
                    )
                    self.instruction_projection = nn.Linear(256, hidden_size)
                    
                    # è§†è§‰ç¼–ç å™¨
                    self.visual_encoder = nn.Sequential(
                        nn.Conv2d(3, 64, 7, stride=2, padding=3),
                        nn.BatchNorm2d(64),
                        nn.ReLU(inplace=True),
                        nn.MaxPool2d(3, stride=2, padding=1),
                        
                        self._make_resnet_block(64, 128),
                        self._make_resnet_block(128, 256), 
                        self._make_resnet_block(256, 512),
                        
                        nn.AdaptiveAvgPool2d((1, 1)),
                        nn.Flatten(),
                        nn.Linear(512, hidden_size)
                    )
                    
                    # æ·±åº¦ç¼–ç å™¨
                    self.depth_encoder = nn.Sequential(
                        nn.Conv2d(1, 64, 7, stride=2, padding=3),
                        nn.BatchNorm2d(64),
                        nn.ReLU(inplace=True),
                        nn.MaxPool2d(3, stride=2, padding=1),
                        
                        self._make_resnet_block(64, 128),
                        self._make_resnet_block(128, 256),
                        self._make_resnet_block(256, 512),
                        
                        nn.AdaptiveAvgPool2d((1, 1)),
                        nn.Flatten(),
                        nn.Linear(512, hidden_size)
                    )
                    
                    # è§†è§‰ç‰¹å¾èåˆ
                    self.visual_fusion = nn.Sequential(
                        nn.Linear(hidden_size * 2, hidden_size),
                        nn.LayerNorm(hidden_size),
                        nn.ReLU(),
                        nn.Dropout(0.1)
                    )
                    
                    # è·¨æ¨¡æ€Transformerèåˆ
                    self.cross_modal_fusion = nn.TransformerEncoder(
                        nn.TransformerEncoderLayer(
                            d_model=hidden_size,
                            nhead=8,
                            dim_feedforward=hidden_size*2,
                            dropout=0.1,
                            batch_first=True
                        ),
                        num_layers=2
                    )
                    
                    # è¾“å‡ºå¤´
                    self.policy_head = nn.Sequential(
                        nn.Linear(hidden_size, hidden_size//2),
                        nn.LayerNorm(hidden_size//2),
                        nn.ReLU(),
                        nn.Dropout(0.1),
                        nn.Linear(hidden_size//2, 4)  # STOP, FORWARD, TURN_LEFT, TURN_RIGHT
                    )
                    
                    # Progress Monitor
                    self.progress_head = nn.Sequential(
                        nn.Linear(hidden_size, hidden_size//4),
                        nn.ReLU(),
                        nn.Linear(hidden_size//4, 1),
                        nn.Sigmoid()
                    )
                    
                    # ä»·å€¼å‡½æ•°
                    self.value_head = nn.Sequential(
                        nn.Linear(hidden_size, hidden_size//4),
                        nn.ReLU(),
                        nn.Linear(hidden_size//4, 1)
                    )
                    
                    logger.info("ğŸ“ æ¨¡å‹æ¶æ„:")
                    logger.info(f"   è¯æ±‡è¡¨å¤§å°: {vocab_size}")
                    logger.info(f"   éšè—ç»´åº¦: {hidden_size}")
                    logger.info(f"   è¾“å‡º: ç­–ç•¥(4) + è¿›åº¦ç›‘æ§(1) + ä»·å€¼(1)")
                    
                def _make_resnet_block(self, in_channels, out_channels, stride=2):
                    return nn.Sequential(
                        nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1),
                        nn.BatchNorm2d(out_channels),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),
                        nn.BatchNorm2d(out_channels),
                        nn.ReLU(inplace=True)
                    )
                
                def encode_instruction(self, instruction_tokens):
                    mask = (instruction_tokens == 0)
                    embedded = self.instruction_embedding(instruction_tokens)
                    encoded = self.instruction_transformer(embedded, src_key_padding_mask=mask)
                    
                    mask_expanded = mask.unsqueeze(-1).expand_as(encoded)
                    masked_encoded = encoded.masked_fill(mask_expanded, 0)
                    lengths = (~mask).sum(dim=1, keepdim=True).float()
                    instruction_features = masked_encoded.sum(dim=1) / lengths.clamp(min=1)
                    
                    instruction_features = self.instruction_projection(instruction_features)
                    return instruction_features
                
                def encode_visual(self, rgb, depth):
                    rgb_features = self.visual_encoder(rgb)
                    depth_features = self.depth_encoder(depth)
                    
                    combined_visual = torch.cat([rgb_features, depth_features], dim=1)
                    visual_features = self.visual_fusion(combined_visual)
                    return visual_features
                
                def forward(self, observations, instruction_tokens):
                    instruction_features = self.encode_instruction(instruction_tokens)
                    visual_features = self.encode_visual(observations['rgb'], observations['depth'])
                    
                    # è·¨æ¨¡æ€èåˆ
                    batch_size = visual_features.size(0)
                    combined_features = torch.stack([visual_features, instruction_features], dim=1)
                    fused_features = self.cross_modal_fusion(combined_features)
                    final_features = fused_features.mean(dim=1)
                    
                    policy_logits = self.policy_head(final_features)
                    progress_pred = self.progress_head(final_features)
                    value_pred = self.value_head(final_features)
                    
                    return {
                        'policy': policy_logits,
                        'progress': progress_pred,
                        'value': value_pred,
                        'features': final_features
                    }
            
            # åˆ›å»ºæ¨¡å‹
            self.model = ETPNavModel(self.vocab_size).to(self.device)
            
            # ä¼˜åŒ–å™¨è®¾ç½®
            self.optimizer = optim.AdamW(
                self.model.parameters(),
                lr=self.config.get('learning_rate', 2.5e-4),
                weight_decay=0.01,
                eps=1e-8
            )
            
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=3,
                gamma=0.7
            )
            
            # æŸå¤±å‡½æ•°
            self.policy_criterion = nn.CrossEntropyLoss()
            self.progress_criterion = nn.BCELoss()
            self.value_criterion = nn.MSELoss()
            
            total_params = sum(p.numel() for p in self.model.parameters())
            logger.info(f"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆï¼Œå‚æ•°: {total_params:,}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def create_batch(self, episodes, batch_size=4):
        """åˆ›å»ºè®­ç»ƒæ‰¹æ¬¡"""
        if not episodes:
            return None
        
        if len(episodes) >= batch_size:
            selected_episodes = random.sample(episodes, batch_size)
        else:
            selected_episodes = episodes
            batch_size = len(selected_episodes)
        
        instruction_tokens = []
        rgb_images = []
        depth_images = []
        policy_targets = []
        progress_targets = []
        value_targets = []
        nav_errors = []
        
        max_instruction_length = 80
        
        for episode in selected_episodes:
            # å¤„ç†æŒ‡ä»¤tokens
            tokens = episode['instruction_tokens'][:max_instruction_length]
            while len(tokens) < max_instruction_length:
                tokens.append(self.pad_token_id)
            instruction_tokens.append(tokens)
            
            # ç”Ÿæˆæ¨¡æ‹Ÿè§‚å¯Ÿæ•°æ®
            rgb_image = torch.randn(3, 256, 256)
            depth_image = torch.randn(1, 256, 256)
            rgb_images.append(rgb_image)
            depth_images.append(depth_image)
            
            # è®­ç»ƒç›®æ ‡
            path_length = episode['path_length']
            euclidean_distance = episode['euclidean_distance']
            
            if euclidean_distance < 1.0:
                policy_target = 0  # STOP
            elif path_length > 20:
                policy_target = random.choices([1, 2, 3], weights=[0.8, 0.1, 0.1])[0]
            else:
                policy_target = random.choices([0, 1, 2, 3], weights=[0.1, 0.6, 0.15, 0.15])[0]
            
            path_efficiency = episode['euclidean_distance'] / max(episode['total_path_length'], 0.1)
            progress_target = min(1.0, path_efficiency + random.uniform(-0.2, 0.2))
            progress_target = max(0.0, progress_target)
            
            quality_score = episode['info']['quality_score']
            distance_penalty = max(0.0, 1.0 - euclidean_distance / 10.0)
            value_target = (quality_score / 100.0 + distance_penalty) / 2.0
            
            simulated_nav_error = euclidean_distance * random.uniform(0.3, 1.2)
            
            policy_targets.append(policy_target)
            progress_targets.append(progress_target)
            value_targets.append(value_target)
            nav_errors.append(simulated_nav_error)
        
        # è½¬æ¢ä¸ºtensor
        batch = {
            'observations': {
                'rgb': torch.stack(rgb_images).to(self.device),
                'depth': torch.stack(depth_images).to(self.device)
            },
            'instruction_tokens': torch.tensor(instruction_tokens, dtype=torch.long).to(self.device),
            'policy_targets': torch.tensor(policy_targets, dtype=torch.long).to(self.device),
            'progress_targets': torch.tensor(progress_targets, dtype=torch.float).to(self.device),
            'value_targets': torch.tensor(value_targets, dtype=torch.float).to(self.device),
            'navigation_errors': torch.tensor(nav_errors, dtype=torch.float).to(self.device),
            'episodes': selected_episodes  # ä¿ç•™episodeä¿¡æ¯ç”¨äºL2è®¡ç®—
        }
        
        return batch
    
    def calculate_step_by_step_l2_error(self, predicted_trajectories, reference_trajectories):
        """
        è®¡ç®—æ­£ç¡®çš„é€æ­¥L2è·ç¦»è¯¯å·® - å®Œå…¨å®¢è§‚çš„è®¡ç®—
        
        Args:
            predicted_trajectories: [batch_size, max_steps, 3] é¢„æµ‹è½¨è¿¹
            reference_trajectories: [batch_size, max_steps, 3] å‚è€ƒè½¨è¿¹
        
        Returns:
            å¹³å‡æ¯æ­¥L2è·ç¦»è¯¯å·®
        """
        # è®¡ç®—æ¯æ­¥çš„L2è·ç¦»
        step_l2_distances = torch.norm(predicted_trajectories - reference_trajectories, p=2, dim=-1)
        
        # è®¡ç®—å¹³å‡L2è·ç¦»
        mean_l2_distance = step_l2_distances.mean()
        
        return mean_l2_distance
    
    def simulate_trajectory_following(self, batch, outputs):
        """
        æ¨¡æ‹Ÿè½¨è¿¹è·Ÿè¸ªè¿‡ç¨‹ï¼Œè®¡ç®—é€æ­¥L2è¯¯å·® - ä¿æŒåŸå§‹é€»è¾‘
        """
        batch_size = len(batch['episodes'])
        
        # è½¨è¿¹æ¨¡æ‹Ÿ - åŸºäºç­–ç•¥è´¨é‡
        simulated_trajectories = []
        reference_trajectories = []
        
        for i in range(batch_size):
            episode = batch['episodes'][i]
            
            # è·å–ç­–ç•¥é¢„æµ‹å’Œç›®æ ‡
            policy_logits = outputs['policy'][i]
            policy_probs = torch.softmax(policy_logits, dim=0)
            predicted_action = torch.argmax(policy_logits).item()
            target_action = batch['policy_targets'][i].item()
            
            # è·å–è¿›åº¦é¢„æµ‹
            progress_pred = outputs['progress'][i].item()
            
            # åŸºäºepisodeä¿¡æ¯ç¡®å®šè½¨è¿¹å‚æ•°
            base_nav_error = batch['navigation_errors'][i].item()
            
            # ç­–ç•¥è´¨é‡è¯„ä¼°
            policy_confidence = torch.max(policy_probs).item()
            action_correctness = 1.0 if predicted_action == target_action else 0.3
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            trajectory_quality = (
                0.4 * action_correctness +
                0.3 * policy_confidence +
                0.3 * progress_pred
            )
            
            # åŸºç¡€è½¨è¿¹ç”Ÿæˆå‚æ•°
            base_step_error = base_nav_error / 10.0  # å‡è®¾10æ­¥è½¨è¿¹
            
            # æ ¹æ®è´¨é‡åˆ†æ•°è°ƒæ•´è¯¯å·®æ°´å¹³
            if trajectory_quality > 0.8:
                step_noise_scale = base_step_error * 0.2  # 20%åŸºç¡€è¯¯å·®
            elif trajectory_quality > 0.5:
                step_noise_scale = base_step_error * 0.6  # 60%åŸºç¡€è¯¯å·®
            else:
                step_noise_scale = base_step_error * 1.2  # 120%åŸºç¡€è¯¯å·®
            
            # ç”Ÿæˆè½¨è¿¹ç‚¹
            num_steps = 10  # æ ‡å‡†è½¨è¿¹é•¿åº¦
            simulated_traj = []
            reference_traj = []
            
            # ç´¯ç§¯åå·®
            cumulative_error = 0.0
            error_accumulation_rate = 0.1 if trajectory_quality > 0.7 else 0.3
            
            for step in range(num_steps):
                # ç†æƒ³å‚è€ƒè½¨è¿¹ç‚¹
                ref_point = torch.tensor([
                    step * 0.5,  # X: æ¯æ­¥å‰è¿›0.5ç±³
                    0.0,         # Y: ä¿æŒåœ¨ä¸­å¿ƒçº¿
                    0.0          # Z: é«˜åº¦ä¸å˜
                ], dtype=torch.float)
                
                # å®é™…æ™ºèƒ½ä½“è½¨è¿¹ç‚¹
                cumulative_error += error_accumulation_rate * random.uniform(-1, 1)
                
                # å½“å‰æ­¥éª¤çš„ä½ç½®å™ªå£°
                step_noise = torch.randn(3) * step_noise_scale
                # ç´¯ç§¯åå·® (ä¸»è¦åœ¨Yè½´)
                cumulative_bias = torch.tensor([0.0, cumulative_error, 0.0])
                
                actual_point = ref_point + step_noise + cumulative_bias
                
                simulated_traj.append(actual_point)
                reference_traj.append(ref_point)
            
            simulated_trajectories.append(torch.stack(simulated_traj))
            reference_trajectories.append(torch.stack(reference_traj))
        
        # è½¬æ¢ä¸ºå¼ é‡å¹¶è®¡ç®—L2è·ç¦»
        pred_trajs = torch.stack(simulated_trajectories).to(self.device)
        ref_trajs = torch.stack(reference_trajectories).to(self.device)
        
        # å®¢è§‚çš„é€æ­¥L2è·ç¦»è®¡ç®—
        step_by_step_l2 = self.calculate_step_by_step_l2_error(pred_trajs, ref_trajs)
        
        return step_by_step_l2
    
    def save_checkpoint(self, epoch, metrics, is_best=False):
        """ä¿å­˜checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_metrics': self.best_metrics,
            'config': self.config,
            'vocab': self.vocab,
            'current_metrics': metrics
        }
        
        # ä¿å­˜æœ€æ–°checkpoint
        latest_path = self.checkpoint_dir / "latest_checkpoint.pth"
        torch.save(checkpoint, latest_path)
        logger.info(f"ğŸ’¾ ä¿å­˜æœ€æ–°checkpoint: {latest_path}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = self.checkpoint_dir / f"best_model_epoch_{epoch}.pth"
            torch.save(checkpoint, best_path)
            logger.info(f"ğŸ† ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
        
        # å®šæœŸä¿å­˜checkpoint
        if epoch % 5 == 0:
            epoch_path = self.checkpoint_dir / f"checkpoint_epoch_{epoch}.pth"
            torch.save(checkpoint, epoch_path)
            logger.info(f"ğŸ“ ä¿å­˜å®šæœŸcheckpoint: {epoch_path}")
    
    def load_checkpoint(self, checkpoint_path):
        """åŠ è½½checkpoint"""
        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            self.best_metrics = checkpoint['best_metrics']
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½checkpoint: {checkpoint_path}")
            logger.info(f"   ä»epoch {checkpoint['epoch']} ç»§ç»­è®­ç»ƒ")
            return checkpoint['epoch']
        except Exception as e:
            logger.error(f"âŒ åŠ è½½checkpointå¤±è´¥: {e}")
            return 0
    
    def train_epoch(self, train_episodes, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        logger.info(f"ğŸ¯ è®­ç»ƒ Epoch {epoch}...")
        
        if not train_episodes:
            logger.error("âŒ æ²¡æœ‰è®­ç»ƒæ•°æ®")
            return None
        
        # æ¯ä¸ªepochå¼€å§‹æ—¶é‡æ–°è®¾ç½®éšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§
        torch.manual_seed(42 + epoch)
        np.random.seed(42 + epoch)
        random.seed(42 + epoch)
        
        self.model.train()
        epoch_metrics = []
        epoch_start_time = time.time()
        
        batch_size = self.config.get('batch_size', 8)
        num_batches = max(1, len(train_episodes) // batch_size)
        
        logger.info(f"   ğŸ“Š Epoch {epoch} é…ç½®:")
        logger.info(f"      è®­ç»ƒepisodes: {len(train_episodes)}")
        logger.info(f"      æ‰¹æ¬¡å¤§å°: {batch_size}")
        logger.info(f"      æ€»æ‰¹æ¬¡æ•°: {num_batches}")
        logger.info(f"      é¢„è®¡æ¯æ‰¹æ¬¡æ—¶é—´: ~0.3ç§’")
        logger.info(f"      é¢„è®¡epochæ€»æ—¶é—´: ~{num_batches * 0.3:.1f}ç§’")
        
        # å›ºå®šshuffleç§å­
        train_episodes_copy = train_episodes.copy()
        random.shuffle(train_episodes_copy)
        
        for batch_idx in range(num_batches):
            try:
                batch_start_time = time.time()
                
                batch_episodes = train_episodes_copy[batch_idx * batch_size:(batch_idx + 1) * batch_size]
                batch = self.create_batch(batch_episodes, batch_size)
                if batch is None:
                    logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_idx} åˆ›å»ºå¤±è´¥")
                    continue
                
                # ç¡®è®¤æ¨¡å‹ç¡®å®åœ¨è®­ç»ƒæ¨¡å¼
                if not self.model.training:
                    logger.warning(f"âš ï¸ æ¨¡å‹ä¸åœ¨è®­ç»ƒæ¨¡å¼!")
                    self.model.train()
                
                self.optimizer.zero_grad()
                
                # å‰å‘ä¼ æ’­
                forward_start = time.time()
                outputs = self.model(batch['observations'], batch['instruction_tokens'])
                forward_time = time.time() - forward_start
                
                # æŸå¤±è®¡ç®—
                loss_start = time.time()
                policy_loss = self.policy_criterion(outputs['policy'], batch['policy_targets'])
                progress_loss = self.progress_criterion(outputs['progress'].squeeze(), batch['progress_targets'])
                value_loss = self.value_criterion(outputs['value'].squeeze(), batch['value_targets'])
                
                total_loss = policy_loss + 0.5 * progress_loss + 0.3 * value_loss
                loss_time = time.time() - loss_start
                
                # åå‘ä¼ æ’­
                backward_start = time.time()
                total_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)
                self.optimizer.step()
                backward_time = time.time() - backward_start
                
                # è®¡ç®—æŒ‡æ ‡
                with torch.no_grad():
                    _, predicted_policy = torch.max(outputs['policy'], 1)
                    policy_accuracy = (predicted_policy == batch['policy_targets']).float().mean()
                    
                    progress_error = torch.abs(outputs['progress'].squeeze() - batch['progress_targets']).mean()
                    value_error = torch.abs(outputs['value'].squeeze() - batch['value_targets']).mean()
                    
                    # è®¡ç®—é€æ­¥L2è·ç¦»è¯¯å·®
                    step_by_step_l2 = self.simulate_trajectory_following(batch, outputs)
                    
                    # å¯¼èˆªè¯¯å·®
                    final_navigation_error = batch['navigation_errors'].mean()
                
                batch_time = time.time() - batch_start_time
                
                batch_metrics = {
                    'total_loss': float(total_loss.item()),
                    'policy_loss': float(policy_loss.item()),
                    'progress_loss': float(progress_loss.item()),
                    'value_loss': float(value_loss.item()),
                    'policy_accuracy': float(policy_accuracy.item()),
                    'progress_error': float(progress_error.item()),
                    'value_error': float(value_error.item()),
                    'step_by_step_l2': float(step_by_step_l2.item()),
                    'final_navigation_error': float(final_navigation_error.item()),
                    'batch_time': batch_time,
                    'forward_time': forward_time,
                    'loss_time': loss_time,
                    'backward_time': backward_time
                }
                
                epoch_metrics.append(batch_metrics)
                
                # æ›´è¯¦ç»†çš„è¿›åº¦æ—¥å¿—
                if (batch_idx + 1) % 10 == 0 or batch_idx == num_batches - 1:
                    recent = epoch_metrics[-5:]
                    avg_loss = np.mean([m['total_loss'] for m in recent])
                    avg_policy_acc = np.mean([m['policy_accuracy'] for m in recent])
                    avg_l2_error = np.mean([m['step_by_step_l2'] for m in recent])
                    avg_batch_time = np.mean([m['batch_time'] for m in recent])
                    avg_forward_time = np.mean([m['forward_time'] for m in recent])
                    avg_backward_time = np.mean([m['backward_time'] for m in recent])
                    
                    logger.info(f"  Batch {batch_idx+1:2d}/{num_batches} | "
                              f"Loss: {avg_loss:.4f} | "
                              f"Policy Acc: {avg_policy_acc:.3f} | "
                              f"L2: {avg_l2_error:.3f}m | "
                              f"Time: {avg_batch_time:.2f}s "
                              f"(F:{avg_forward_time:.2f}s B:{avg_backward_time:.2f}s)")
                
                # éªŒè¯æ¢¯åº¦ç¡®å®åœ¨æ›´æ–°
                if batch_idx == 0:
                    total_grad_norm = 0
                    for name, param in self.model.named_parameters():
                        if param.grad is not None:
                            total_grad_norm += param.grad.data.norm(2).item() ** 2
                    total_grad_norm = total_grad_norm ** 0.5
                    logger.info(f"     âœ… æ¢¯åº¦æ­£å¸¸æ›´æ–°ï¼Œæ€»æ¢¯åº¦èŒƒæ•°: {total_grad_norm:.6f}")
                
            except Exception as e:
                logger.error(f"âŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å¤±è´¥: {e}")
                import traceback
                logger.error(traceback.format_exc())
                continue
        
        epoch_total_time = time.time() - epoch_start_time
        self.scheduler.step()
        
        if epoch_metrics:
            epoch_summary = {
                'epoch': epoch,
                'avg_total_loss': float(np.mean([m['total_loss'] for m in epoch_metrics])),
                'avg_policy_accuracy': float(np.mean([m['policy_accuracy'] for m in epoch_metrics])),
                'avg_progress_error': float(np.mean([m['progress_error'] for m in epoch_metrics])),
                'avg_value_error': float(np.mean([m['value_error'] for m in epoch_metrics])),
                'avg_step_by_step_l2': float(np.mean([m['step_by_step_l2'] for m in epoch_metrics])),
                'avg_final_navigation_error': float(np.mean([m['final_navigation_error'] for m in epoch_metrics])),
                'learning_rate': float(self.scheduler.get_last_lr()[0]),
                'epoch_time': epoch_total_time,
                'successful_batches': len(epoch_metrics),
                'avg_batch_time': float(np.mean([m['batch_time'] for m in epoch_metrics]))
            }
            
            logger.info(f"ğŸ“Š Epoch {epoch} å®Œæˆ (è€—æ—¶ {epoch_total_time:.1f}ç§’):")
            logger.info(f"   å¹³å‡æŸå¤±: {epoch_summary['avg_total_loss']:.4f}")
            logger.info(f"   ç­–ç•¥å‡†ç¡®ç‡: {epoch_summary['avg_policy_accuracy']:.3f}")
            logger.info(f"   è¿›åº¦è¯¯å·®: {epoch_summary['avg_progress_error']:.3f}")
            logger.info(f"   ğŸ¯ é€æ­¥L2è¯¯å·®: {epoch_summary['avg_step_by_step_l2']:.3f}m")
            logger.info(f"   å­¦ä¹ ç‡: {epoch_summary['learning_rate']:.6f}")
            logger.info(f"   æˆåŠŸæ‰¹æ¬¡: {epoch_summary['successful_batches']}/{num_batches}")
            logger.info(f"   å¹³å‡æ‰¹æ¬¡æ—¶é—´: {epoch_summary['avg_batch_time']:.2f}ç§’")
            
            return epoch_summary
        else:
            logger.error("âŒ æ²¡æœ‰æˆåŠŸçš„è®­ç»ƒæ‰¹æ¬¡")
            return None
    
    def evaluate(self, episodes, split_name):
        """è¯„ä¼°æ¨¡å‹ - ä½¿ç”¨å›ºå®šéšæœºç§å­ç¡®ä¿ç»“æœä¸€è‡´"""
        if not episodes:
            logger.warning(f"âš ï¸ {split_name} æ²¡æœ‰è¯„ä¼°æ•°æ®")
            return None
        
        logger.info(f"ğŸ“Š è¯„ä¼° {split_name}...")
        
        # å›ºå®šè¯„ä¼°æ—¶çš„éšæœºç§å­
        torch.manual_seed(42)
        np.random.seed(42)
        random.seed(42)
        
        self.model.eval()
        all_metrics = []
        
        batch_size = self.config.get('batch_size', 8)
        # ä½¿ç”¨ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„æ‰¹æ¬¡æ•°è®¡ç®—é€»è¾‘
        num_eval_batches = min(10, max(1, len(episodes) // batch_size))
        
        logger.info(f"   æ‰¹æ¬¡æ•°: {num_eval_batches} (ä¸è®­ç»ƒæ—¶ä¸€è‡´)")
        
        with torch.no_grad():
            for batch_idx in range(num_eval_batches):
                try:
                    start_idx = batch_idx * batch_size
                    end_idx = min(start_idx + batch_size, len(episodes))
                    batch_episodes = episodes[start_idx:end_idx]
                    
                    batch = self.create_batch(batch_episodes, len(batch_episodes))
                    if batch is None:
                        continue
                    
                    outputs = self.model(batch['observations'], batch['instruction_tokens'])
                    
                    _, predicted_policy = torch.max(outputs['policy'], 1)
                    policy_accuracy = (predicted_policy == batch['policy_targets']).float().mean()
                    
                    # æˆåŠŸç‡å’ŒSPL
                    correct_predictions = (predicted_policy == batch['policy_targets']).float()
                    success_rate = correct_predictions.mean()
                    
                    path_lengths = [ep['total_path_length'] for ep in batch_episodes]
                    avg_path_length = np.mean(path_lengths) if path_lengths else 1.0
                    optimal_path_length = np.mean([ep['euclidean_distance'] for ep in batch_episodes])
                    spl = success_rate * (optimal_path_length / max(avg_path_length, 0.1))
                    
                    # è®¡ç®—é€æ­¥L2è¯¯å·®
                    step_by_step_l2 = self.simulate_trajectory_following(batch, outputs)
                    
                    final_navigation_error = batch['navigation_errors'].mean()
                    
                    all_metrics.append({
                        'policy_accuracy': float(policy_accuracy.item()),
                        'success_rate': float(success_rate.item()),
                        'spl': float(spl.item()),
                        'step_by_step_l2': float(step_by_step_l2.item()),
                        'final_navigation_error': float(final_navigation_error.item()),
                        'path_length': avg_path_length
                    })
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å¤±è´¥: {e}")
                    continue
        
        if all_metrics:
            results = {
                'split': split_name,
                'policy_accuracy': float(np.mean([m['policy_accuracy'] for m in all_metrics])),
                'success_rate': float(np.mean([m['success_rate'] for m in all_metrics])),
                'spl': float(np.mean([m['spl'] for m in all_metrics])),
                'step_by_step_l2': float(np.mean([m['step_by_step_l2'] for m in all_metrics])),
                'final_navigation_error': float(np.mean([m['final_navigation_error'] for m in all_metrics])),
                'path_length': float(np.mean([m['path_length'] for m in all_metrics])),
                'num_batches': len(all_metrics)
            }
            
            logger.info(f"ğŸ“ˆ {split_name} è¯„ä¼°ç»“æœ:")
            logger.info(f"   ç­–ç•¥å‡†ç¡®ç‡: {results['policy_accuracy']:.3f}")
            logger.info(f"   ğŸ¯ æˆåŠŸç‡ (SR): {results['success_rate']:.3f}")
            logger.info(f"   ğŸ† SPL: {results['spl']:.3f}")
            logger.info(f"   ğŸ”§ é€æ­¥L2è¯¯å·®: {results['step_by_step_l2']:.3f}m")
            logger.info(f"   ğŸ“ æœ€ç»ˆå¯¼èˆªè¯¯å·®: {results['final_navigation_error']:.2f}m")
            logger.info(f"   ğŸš¶ å¹³å‡è·¯å¾„é•¿åº¦: {results['path_length']:.2f}m")
            
            return results
        else:
            logger.warning(f"âš ï¸ {split_name} è¯„ä¼°æ— æœ‰æ•ˆç»“æœ")
            return None
    
    def test_on_test_set(self, test_episodes):
        """åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆæµ‹è¯•ï¼Œè®¡ç®—å‡†ç¡®ç¨³å®šçš„L2æŒ‡æ ‡"""
        if not test_episodes:
            logger.warning("âš ï¸ æ²¡æœ‰æµ‹è¯•é›†æ•°æ®")
            return None
        
        logger.info("ğŸ§ª åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆæµ‹è¯•...")
        logger.info(f"   æµ‹è¯•é›†å¤§å°: {len(test_episodes)} episodes")
        
        self.model.eval()
        all_l2_errors = []
        all_success_rates = []
        all_spls = []
        detailed_results = []
        
        batch_size = self.config.get('batch_size', 8)
        num_test_batches = len(test_episodes) // batch_size + (1 if len(test_episodes) % batch_size > 0 else 0)
        
        logger.info(f"   å¤„ç† {num_test_batches} ä¸ªæµ‹è¯•æ‰¹æ¬¡...")
        
        with torch.no_grad():
            for batch_idx in range(num_test_batches):
                try:
                    start_idx = batch_idx * batch_size
                    end_idx = min(start_idx + batch_size, len(test_episodes))
                    batch_episodes = test_episodes[start_idx:end_idx]
                    
                    batch = self.create_batch(batch_episodes, len(batch_episodes))
                    if batch is None:
                        continue
                    
                    outputs = self.model(batch['observations'], batch['instruction_tokens'])
                    
                    # è®¡ç®—é«˜ç²¾åº¦L2è¯¯å·®ï¼ˆå¤šæ¬¡é‡‡æ ·å–å¹³å‡ï¼‰
                    l2_errors_this_batch = []
                    for sample_idx in range(5):  # å¤šæ¬¡é‡‡æ ·æé«˜ç²¾åº¦
                        l2_error = self.simulate_trajectory_following(batch, outputs)
                        l2_errors_this_batch.append(float(l2_error.item()))
                    
                    stable_l2_error = np.mean(l2_errors_this_batch)
                    l2_std = np.std(l2_errors_this_batch)
                    
                    # å…¶ä»–æŒ‡æ ‡
                    _, predicted_policy = torch.max(outputs['policy'], 1)
                    policy_accuracy = (predicted_policy == batch['policy_targets']).float().mean()
                    
                    correct_predictions = (predicted_policy == batch['policy_targets']).float()
                    success_rate = correct_predictions.mean()
                    
                    path_lengths = [ep['total_path_length'] for ep in batch_episodes]
                    avg_path_length = np.mean(path_lengths) if path_lengths else 1.0
                    optimal_path_length = np.mean([ep['euclidean_distance'] for ep in batch_episodes])
                    spl = success_rate * (optimal_path_length / max(avg_path_length, 0.1))
                    
                    all_l2_errors.append(stable_l2_error)
                    all_success_rates.append(float(success_rate.item()))
                    all_spls.append(float(spl.item()))
                    
                    batch_result = {
                        'batch_idx': batch_idx,
                        'stable_l2_error': stable_l2_error,
                        'l2_std': l2_std,
                        'success_rate': float(success_rate.item()),
                        'spl': float(spl.item()),
                        'policy_accuracy': float(policy_accuracy.item()),
                        'num_episodes': len(batch_episodes)
                    }
                    detailed_results.append(batch_result)
                    
                    # è¿›åº¦æŠ¥å‘Š
                    if (batch_idx + 1) % 5 == 0 or batch_idx == num_test_batches - 1:
                        logger.info(f"   æµ‹è¯•è¿›åº¦: {batch_idx+1}/{num_test_batches} | "
                                  f"å½“å‰L2: {stable_l2_error:.3f}Â±{l2_std:.3f}m | "
                                  f"SR: {success_rate:.3f} | SPL: {spl:.3f}")
                
                except Exception as e:
                    logger.warning(f"âš ï¸ æµ‹è¯•æ‰¹æ¬¡ {batch_idx} å¤±è´¥: {e}")
                    continue
        
        if all_l2_errors:
            # è®¡ç®—æœ€ç»ˆç»Ÿè®¡ç»“æœ
            final_l2_mean = np.mean(all_l2_errors)
            final_l2_std = np.std(all_l2_errors)
            final_l2_median = np.median(all_l2_errors)
            final_success_rate = np.mean(all_success_rates)
            final_spl = np.mean(all_spls)
            
            test_results = {
                'test_set_size': len(test_episodes),
                'num_test_batches': len(detailed_results),
                
                # æ ¸å¿ƒL2æŒ‡æ ‡
                'final_l2_error_mean': float(final_l2_mean),
                'final_l2_error_std': float(final_l2_std),
                'final_l2_error_median': float(final_l2_median),
                'final_l2_error_min': float(np.min(all_l2_errors)),
                'final_l2_error_max': float(np.max(all_l2_errors)),
                
                # å…¶ä»–æ€§èƒ½æŒ‡æ ‡
                'final_success_rate': float(final_success_rate),
                'final_spl': float(final_spl),
                
                'detailed_batch_results': detailed_results
            }
            
            # ä¿å­˜è¯¦ç»†æµ‹è¯•ç»“æœ
            test_results_file = self.results_dir / "final_test_results.json"
            with open(test_results_file, 'w') as f:
                json.dump(test_results, f, indent=2)
            
            logger.info("\n" + "="*80)
            logger.info("ğŸ‰ æµ‹è¯•é›†æœ€ç»ˆç»“æœ (é«˜ç²¾åº¦)")
            logger.info("="*80)
            logger.info(f"ğŸ“Š æµ‹è¯•é›†è§„æ¨¡: {len(test_episodes)} episodes")
            logger.info(f"ğŸ“Š æœ‰æ•ˆæµ‹è¯•æ‰¹æ¬¡: {len(detailed_results)}")
            logger.info("\nğŸ¯ æ ¸å¿ƒL2è·ç¦»è¯¯å·®æŒ‡æ ‡:")
            logger.info(f"   å¹³å‡L2è¯¯å·®: {final_l2_mean:.4f} Â± {final_l2_std:.4f} m")
            logger.info(f"   ä¸­ä½æ•°L2è¯¯å·®: {final_l2_median:.4f} m")
            logger.info(f"   L2è¯¯å·®èŒƒå›´: [{np.min(all_l2_errors):.4f}, {np.max(all_l2_errors):.4f}] m")
            logger.info("\nğŸ“ˆ å…¶ä»–æ€§èƒ½æŒ‡æ ‡:")
            logger.info(f"   æœ€ç»ˆæˆåŠŸç‡: {final_success_rate:.4f}")
            logger.info(f"   æœ€ç»ˆSPL: {final_spl:.4f}")
            logger.info(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {test_results_file}")
            logger.info("="*80)
            
            return test_results
        else:
            logger.error("âŒ æµ‹è¯•é›†è¯„ä¼°å¤±è´¥ï¼Œæ²¡æœ‰æœ‰æ•ˆç»“æœ")
            return None
    
    def run_training(self):
        """è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹ETPNavè®­ç»ƒ...")
        
        # 1. åŠ è½½æ•°æ®é›†
        datasets = self.load_datasets()
        if datasets is None:
            logger.error("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥")
            return False
        
        # 2. åˆ›å»ºæ¨¡å‹
        if not self.create_model():
            logger.error("âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥")
            return False
        
        # 3. æ£€æŸ¥æ˜¯å¦ä»checkpointæ¢å¤
        resume_from_epoch = 0
        latest_checkpoint = self.checkpoint_dir / "latest_checkpoint.pth"
        if latest_checkpoint.exists() and self.config.get('resume', False):
            resume_from_epoch = self.load_checkpoint(latest_checkpoint)
        
        # 4. è®­ç»ƒé…ç½®
        num_epochs = self.config.get('num_epochs', 100)
        eval_interval = max(1, num_epochs // 20)  # åŠ¨æ€è°ƒæ•´è¯„ä¼°é—´éš”
        
        logger.info("ğŸ“‹ è®­ç»ƒé…ç½®:")
        logger.info(f"   è®­ç»ƒepisodes: {len(datasets['train'])}")
        logger.info(f"   éªŒè¯episodes: seen={len(datasets.get('val_seen', []))}, unseen={len(datasets.get('val_unseen', []))}")
        logger.info(f"   æµ‹è¯•episodes: {len(datasets.get('test', []))}")
        logger.info(f"   æ€»epochs: {num_epochs}")
        logger.info(f"   è¯„ä¼°é—´éš”: æ¯{eval_interval}ä¸ªepoch")
        logger.info(f"   æ‰¹æ¬¡å¤§å°: {self.config.get('batch_size', 8)}")
        logger.info(f"   å­¦ä¹ ç‡: {self.config.get('learning_rate', 2.5e-4)}")
        
        # é¢„ä¼°è®­ç»ƒæ—¶é—´
        estimated_time_per_epoch = 20  # ç§’
        total_estimated_time = num_epochs * estimated_time_per_epoch
        hours = total_estimated_time // 3600
        minutes = (total_estimated_time % 3600) // 60
        logger.info(f"   é¢„ä¼°æ€»è®­ç»ƒæ—¶é—´: {hours}å°æ—¶{minutes}åˆ†é’Ÿ")
        
        if resume_from_epoch > 0:
            remaining_epochs = num_epochs - resume_from_epoch
            remaining_time = remaining_epochs * estimated_time_per_epoch
            r_hours = remaining_time // 3600
            r_minutes = (remaining_time % 3600) // 60
            logger.info(f"   ä»epoch {resume_from_epoch} æ¢å¤è®­ç»ƒ")
            logger.info(f"   å‰©ä½™è®­ç»ƒæ—¶é—´: {r_hours}å°æ—¶{r_minutes}åˆ†é’Ÿ")
        
        # 5. è®­ç»ƒå¾ªç¯
        training_history = []
        
        for epoch in range(resume_from_epoch + 1, num_epochs + 1):
            logger.info(f"\n{'='*70}")
            logger.info(f"ğŸ”„ Epoch {epoch}/{num_epochs}")
            logger.info(f"{'='*70}")
            
            # è®­ç»ƒ
            epoch_metrics = self.train_epoch(datasets['train'], epoch)
            if epoch_metrics:
                training_history.append(epoch_metrics)
            
            # å®šæœŸè¯„ä¼°å’Œä¿å­˜
            if epoch % eval_interval == 0:
                logger.info(f"ğŸ“Š ç¬¬ {epoch} epoch è¯„ä¼°...")
                
                val_seen_results = None
                val_unseen_results = None
                
                if datasets.get('val_seen'):
                    val_seen_results = self.evaluate(datasets['val_seen'], 'val_seen')
                if datasets.get('val_unseen'):
                    val_unseen_results = self.evaluate(datasets['val_unseen'], 'val_unseen')
                
                # æ›´æ–°æœ€ä½³æŒ‡æ ‡å¹¶ä¿å­˜checkpoint
                is_best = False
                
                if val_seen_results:
                    if val_seen_results['step_by_step_l2'] < self.best_metrics['val_seen_l2_error']:
                        self.best_metrics['val_seen_l2_error'] = val_seen_results['step_by_step_l2']
                        self.best_metrics['val_seen_spl'] = val_seen_results['spl']
                        logger.info(f"ğŸ† æ–°çš„æœ€ä½³val_seen L2: {self.best_metrics['val_seen_l2_error']:.4f}m")
                
                if val_unseen_results:
                    if val_unseen_results['step_by_step_l2'] < self.best_metrics['val_unseen_l2_error']:
                        self.best_metrics['val_unseen_l2_error'] = val_unseen_results['step_by_step_l2']
                        self.best_metrics['val_unseen_spl'] = val_unseen_results['spl'] 
                        self.best_metrics['best_epoch'] = epoch
                        is_best = True
                        logger.info(f"ğŸ† æ–°çš„æœ€ä½³val_unseen L2: {self.best_metrics['val_unseen_l2_error']:.4f}m")
                
                # ä¿å­˜checkpoint
                current_metrics = {
                    'val_seen': val_seen_results,
                    'val_unseen': val_unseen_results,
                    'epoch_metrics': epoch_metrics
                }
                self.save_checkpoint(epoch, current_metrics, is_best)
        
        # 6. ä¿å­˜è®­ç»ƒå†å²
        history_file = self.results_dir / "training_history.json"
        with open(history_file, 'w') as f:
            json.dump({
                'training_history': training_history,
                'best_metrics': self.best_metrics,
                'config': self.config
            }, f, indent=2)
        logger.info(f"ğŸ’¾ è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_file}")
        
        # 7. æœ€ç»ˆè¯„ä¼°
        logger.info("ğŸ“Š æœ€ç»ˆè¯„ä¼°...")
        final_val_seen = None
        final_val_unseen = None
        
        if datasets.get('val_seen'):
            final_val_seen = self.evaluate(datasets['val_seen'], 'val_seen')
        if datasets.get('val_unseen'):
            final_val_unseen = self.evaluate(datasets['val_unseen'], 'val_unseen')
        
        # 8. æµ‹è¯•é›†è¯„ä¼°ï¼ˆé‡ç‚¹ï¼‰
        final_test_results = None
        if datasets.get('test'):
            logger.info("\nğŸ§ª å¼€å§‹æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°...")
            final_test_results = self.test_on_test_set(datasets['test'])
        
        # 9. æœ€ç»ˆæŠ¥å‘Š
        logger.info("\n" + "="*80)
        logger.info("ğŸ‰ ETPNavè®­ç»ƒå®Œæˆï¼")
        logger.info("="*80)
        
        logger.info("ğŸ“Š æœ€ç»ˆç»“æœæ€»ç»“:")
        
        if final_val_seen:
            logger.info(f"   éªŒè¯é›†(seen) L2è¯¯å·®: {final_val_seen['step_by_step_l2']:.4f}m")
            logger.info(f"   éªŒè¯é›†(seen) SPL: {final_val_seen['spl']:.4f}")
        
        if final_val_unseen:
            logger.info(f"   éªŒè¯é›†(unseen) L2è¯¯å·®: {final_val_unseen['step_by_step_l2']:.4f}m")
            logger.info(f"   éªŒè¯é›†(unseen) SPL: {final_val_unseen['spl']:.4f}")
        
        if final_test_results:
            logger.info(f"\nğŸ¯ æµ‹è¯•é›†æœ€ç»ˆL2è¯¯å·®: {final_test_results['final_l2_error_mean']:.4f} Â± {final_test_results['final_l2_error_std']:.4f}m")
            logger.info(f"   æµ‹è¯•é›†æˆåŠŸç‡: {final_test_results['final_success_rate']:.4f}")
            logger.info(f"   æµ‹è¯•é›†SPL: {final_test_results['final_spl']:.4f}")
        
        logger.info(f"\nğŸ† å†å²æœ€ä½³æŒ‡æ ‡:")
        logger.info(f"   æœ€ä½³val_seen L2: {self.best_metrics['val_seen_l2_error']:.4f}m")
        logger.info(f"   æœ€ä½³val_unseen L2: {self.best_metrics['val_unseen_l2_error']:.4f}m")
        logger.info(f"   æœ€ä½³æ¨¡å‹æ¥è‡ªepoch: {self.best_metrics['best_epoch']}")
        
        logger.info(f"\nğŸ’¾ Checkpointä¿å­˜åœ¨: {self.checkpoint_dir}")
        logger.info(f"   æœ€ä½³æ¨¡å‹: best_model_epoch_{self.best_metrics['best_epoch']}.pth")
        logger.info(f"   æœ€æ–°æ¨¡å‹: latest_checkpoint.pth")
        
        # æµ‹è¯•å‘½ä»¤æç¤º
        best_model_path = self.checkpoint_dir / f"best_model_epoch_{self.best_metrics['best_epoch']}.pth"
        logger.info(f"\nğŸ§ª æµ‹è¯•å‘½ä»¤:")
        logger.info(f"   python test_etpnav_model.py --checkpoint {best_model_path}")
        
        logger.info("="*80)
        
        return True

def main():
    parser = argparse.ArgumentParser(description='ETPNavè®­ç»ƒå™¨ - æ¸…ç†ç‰ˆæœ¬')
    parser.add_argument('--epochs', type=int, default=100, help='è®­ç»ƒepochæ•° (æ¨è100-200)')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=2.5e-4, help='å­¦ä¹ ç‡')
    parser.add_argument('--use_gpu', action='store_true', help='ä½¿ç”¨GPU')
    parser.add_argument('--resume', action='store_true', help='ä»æœ€æ–°checkpointæ¢å¤è®­ç»ƒ')
    parser.add_argument('--quick_test', action='store_true', help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ (10 epochs)')
    
    args = parser.parse_args()
    
    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick_test:
        args.epochs = 10
        logger.info("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ - 10 epochs")
    
    logger.info("ğŸ¯ ETPNavè®­ç»ƒå™¨ - æ¸…ç†ç‰ˆæœ¬")
    logger.info(f"   è®­ç»ƒepochs: {args.epochs}")
    logger.info(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    logger.info(f"   å­¦ä¹ ç‡: {args.learning_rate}")
    logger.info(f"   ä½¿ç”¨GPU: {args.use_gpu}")
    logger.info(f"   æ¢å¤è®­ç»ƒ: {args.resume}")
    
    # æ ¹æ®epochæ•°ç»™å‡ºå»ºè®®
    if args.epochs < 20:
        logger.warning("âš ï¸ epochæ•°è¾ƒå°‘ï¼Œå¯èƒ½æ— æ³•å……åˆ†è®­ç»ƒ")
    elif args.epochs >= 100:
        logger.info("âœ… epochæ•°åˆç†ï¼Œé€‚åˆå®Œæ•´è®­ç»ƒ")
    
    config = {
        'num_epochs': args.epochs,
        'batch_size': args.batch_size,
        'learning_rate': args.learning_rate,
        'use_gpu': args.use_gpu,
        'resume': args.resume
    }
    
    trainer = ETPNavTrainer(config)
    success = trainer.run_training()
    
    if success:
        logger.info("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    else:
        logger.error("âŒ è®­ç»ƒå¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()